{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime as dt\n",
    "import argparse\n",
    "import re\n",
    "import copy\n",
    "import os\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to break skills, order them and concetenate. order is important so that skill_a+skill_b is the same as skill_B+skill_a\n",
    "def concetanete_skills(skills):\n",
    "    if skills is None or skills is np.nan:\n",
    "        return skills\n",
    "    skills = skills.split('~~')\n",
    "    skills = sorted(skills)\n",
    "    return '+'.join(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logProgressToWfl(progressMsg):\n",
    "    logFile = open(\"multiskillConverterLog.wfl\", \"a\")\n",
    "    now = dt.datetime.now()\n",
    "    progressPrepend = \"%Progress::\"\n",
    "    logFile.write(progressPrepend + \"@\" + str(now) + \"@\" + progressMsg + \"\\n\");\n",
    "    logFile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C:/ProgramData/Anaconda3/Python multiskill_converter.py -programDir . -workingDir . -userId 1 -kcModelsToConvert_nodeIndex 0 -kcModelsToConvert_fileIndex 0 -kcModelsToConvert \"KC (CCSS)\" -kcModelsToConvert_nodeIndex 0 -kcModelsToConvert_fileIndex 0 -kcModelsToConvert \"KC (MATHia New)\" -multiskillConversionMethod \"Concatenate\" -node 0 -fileIndex 0 C:\\WPIDevelopment\\dev06_dev\\WorkflowComponents\\MultiskillConverter\\test\\test_data\\test.txt -inputFile test.txt\n",
    "#C:/ProgramData/Anaconda3/Python multiskill_converter.py -programDir . -workingDir . -userId 1 -kcModelToConvert_nodeIndex 0 -kcModelToConvert_fileIndex 0 -kcModelToConvert \"KC (MATHia New)\" -multiskillConversionMethod \"Split to Multiple Rows\" -valuesToBeSplit_nodeIndex 0 -valuesToBeSplit_fileIndex 0 -valuesToBeSplit \"Correct Step Duration (sec)\" -valuesToBeSplit_nodeIndex 0 -valuesToBeSplit_fileIndex 0 -valuesToBeSplit \"Step Duration (sec)\" -node 0 -fileIndex 0 C:\\WPIDevelopment\\dev06_dev\\WorkflowComponents\\MultiskillConverter\\test\\test_data\\test.txt -inputFile test.txt\n",
    "#C:/ProgramData/Anaconda3/Python multiskill_converter.py -programDir . -workingDir . -userId 1 -kcModelToConvert_nodeIndex 0 -kcModelToConvert_fileIndex 0 -kcModelToConvert \"KC (MATHia New)\" -multiskillConversionMethod \"Split to Multiple Rows\" -valuesToBeSplit_nodeIndex 0 -valuesToBeSplit_fileIndex 0 -valuesToBeSplit \"Step End Time\" -valuesToBeSplit_nodeIndex 0 -valuesToBeSplit_fileIndex 0 -valuesToBeSplit \"Step Duration (sec)\" -node 0 -fileIndex 0 C:\\WPIDevelopment\\dev06_dev\\WorkflowComponents\\MultiskillConverter\\test\\test_data\\test.txt -inputFile test.txt\n",
    "\n",
    "#command line\n",
    "parser = argparse.ArgumentParser(description='Process datashop file.')\n",
    "parser.add_argument('-programDir', type=str, help='the component program directory')\n",
    "parser.add_argument('-workingDir', type=str, help='the component instance working directory')\n",
    "parser.add_argument(\"-node\", nargs=1, action='append')\n",
    "parser.add_argument(\"-fileIndex\", nargs=2, action='append')\n",
    "parser.add_argument('-multiskillConversionMethod', choices=[\"Concatenate\", \"Split to Multiple Rows\"], help='Method to handle multiskill steps(default=\"Concatenate\")', default=\"Concatenate\")\n",
    "parser.add_argument('-kcModelsToConvert', nargs=1, action='append', type=str, help='KC models to convert when concatenating; e.g., \"Item\"')\n",
    "parser.add_argument('-kcModelToConvert', nargs=1, type=str, help='KC model to convert when Split to Multiple Rows; e.g., \"Item\"')\n",
    "parser.add_argument('-valuesToBeSplit', nargs=1, action='append', type=str, help='KC model to convert when Split to Multiple Rows;')\n",
    "parser.add_argument('-averageColumnValues', choices=[\"Yes\", \"No\"], help='If any column value should be averaged(default=\"No\")', default=\"Concatenate\")\n",
    "parser.add_argument('-inputFile', type=str, help='data file containing multi-skill steps')\n",
    "parser.add_argument('-userId', type=str,  help='placeholder for WF', default='')\n",
    "args, option_file_index_args = parser.parse_known_args()\n",
    "filename = args.inputFile\n",
    "modification_method = args.multiskillConversionMethod\n",
    "kcms_to_change = args.kcModelsToConvert\n",
    "if kcms_to_change is not None:\n",
    "    kcms_to_change = list(chain.from_iterable(kcms_to_change))\n",
    "kcm_to_split = args.kcModelToConvert\n",
    "if kcm_to_split is not None:\n",
    "    kcm_to_split = kcm_to_split[0]\n",
    "columns_value_to_be_split = args.valuesToBeSplit\n",
    "if columns_value_to_be_split is not None:\n",
    "    columns_value_to_be_split = list(chain.from_iterable(columns_value_to_be_split))\n",
    "average_column_values = args.averageColumnValues\n",
    "if average_column_values is not None and average_column_values == \"Yes\":\n",
    "    average_column_values = True\n",
    "else:\n",
    "    average_column_values = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    filename = 'test.txt'\n",
    "\n",
    "    #modification_method = 'Concatenate'\n",
    "    kcms_to_change = ['KC (CCSS)', 'KC (MATHia New)']\n",
    "    modification_method = 'Split to Multiple Rows'\n",
    "    kcm_to_split = 'KC (MATHia New)'\n",
    "    columns_value_to_be_split = ['Step Duration (sec)', 'Correct Step Duration (sec)']\n",
    "    average_column_values = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename, dtype=str, na_values = ['null', 'na', 'NA', 'n/a', 'nan'], sep=\"\\t\", encoding = \"ISO-8859-1\")\n",
    "if modification_method == 'Concatenate':\n",
    "    for kcm_to_change in kcms_to_change:\n",
    "        print(kcm_to_change)\n",
    "        if kcm_to_change in df.columns:\n",
    "            #change ~~ to +\n",
    "            df[kcm_to_change] = df[kcm_to_change].apply(concetanete_skills)\n",
    "            #get KC model name without prefix \"KC(\"\"\n",
    "            kcm_name = kcm_to_change\n",
    "            if \"KC (\" in kcm_to_change and \")\" in kcm_to_change:\n",
    "                kc_name = kcm_to_change[len(\"KC (\"):kcm_to_change.find(\")\")]\n",
    "            kcm_opportunity = \"Opportunity ({})\".format(kc_name)\n",
    "            if kcm_opportunity in df.columns:\n",
    "                df.drop(kcm_opportunity, axis=1, inplace=True)\n",
    "            df_omit_na = df[['Anon Student Id', kcm_to_change]]\n",
    "            df_omit_na = df_omit_na.dropna()\n",
    "            df_omit_na[kcm_opportunity] = df_omit_na.groupby(['Anon Student Id', kcm_to_change]).cumcount()+1\n",
    "            df_omit_na = df_omit_na[[kcm_opportunity]]\n",
    "            df = df.merge(df_omit_na, left_index=True, right_index=True, how='left')\n",
    "    filename = os.path.basename(os.path.normpath(filename))\n",
    "    df.to_csv('multiskill_converted_{}'.format(filename), sep='\\t', index=False)\n",
    "\n",
    "elif modification_method == 'Split to Multiple Rows':\n",
    "    proc_pct = 0.1\n",
    "    totalCnt = df.shape[0]\n",
    "    if kcm_to_split in df.columns:\n",
    "        #make a new dataframe\n",
    "        split_df = pd.DataFrame(columns = df.columns)\n",
    "        #loop through each rows\n",
    "        cnt = 1\n",
    "        for index, row in df.iterrows():\n",
    "            #write to the workflow log for percentage processed\n",
    "            if cnt/totalCnt > proc_pct:\n",
    "                logProgressToWfl(\"{:.0%}\".format(proc_pct))\n",
    "                proc_pct = proc_pct + 0.1\n",
    "            cnt = cnt + 1\n",
    "            #process skills\n",
    "            skills = row[kcm_to_split]\n",
    "            if skills is None or pd.isna(skills):\n",
    "                split_df = split_df.append(row, ignore_index = True)\n",
    "                continue\n",
    "            skills = row[kcm_to_split].split('~~')\n",
    "            for skill in skills:\n",
    "                row_as_dict = {}\n",
    "                for column in df.columns:\n",
    "                    if column == kcm_to_split:\n",
    "                        row_as_dict[kcm_to_split] = skill\n",
    "                    elif average_column_values == True and column in columns_value_to_be_split:\n",
    "                        val_to_split = row[column]\n",
    "                        if val_to_split is not None and not pd.isna(val_to_split):\n",
    "                            try:\n",
    "                                val = pd.to_numeric(val_to_split)\n",
    "                                row_as_dict[column] = val/len(skills)\n",
    "                            except:\n",
    "                                row_as_dict[column] = row[column]\n",
    "                        else:\n",
    "                            row_as_dict[column] = row[column]\n",
    "                    else:\n",
    "                        row_as_dict[column] = row[column]\n",
    "                split_df = split_df.append(row_as_dict, ignore_index = True)\n",
    "        #redo opportunity\n",
    "        kcm_name = kcm_to_split\n",
    "        if \"KC (\" in kcm_to_split and \")\" in kcm_to_split:\n",
    "            kc_name = kcm_to_split[len(\"KC (\"):kcm_to_split.find(\")\")]\n",
    "        kcm_opportunity = \"Opportunity ({})\".format(kc_name)\n",
    "        if kcm_opportunity in split_df.columns:\n",
    "            split_df.drop(kcm_opportunity, axis=1, inplace=True)\n",
    "        df_omit_na = split_df[['Anon Student Id', kcm_to_split]]\n",
    "        df_omit_na = df_omit_na.dropna()\n",
    "        df_omit_na[kcm_opportunity] = df_omit_na.groupby(['Anon Student Id', kcm_to_split]).cumcount()+1\n",
    "        df_omit_na = df_omit_na[[kcm_opportunity]]\n",
    "        split_df = split_df.merge(df_omit_na, left_index=True, right_index=True, how='left')\n",
    "        filename = os.path.basename(os.path.normpath(filename))\n",
    "        split_df.to_csv('multiskill_converted_{}'.format(filename), sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
