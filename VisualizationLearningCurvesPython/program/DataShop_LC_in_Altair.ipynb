{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1We3tpFGkuVO",
    "outputId": "d64f2a03-56de-4d06-a057-8e0b2fb5e04c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import argparse\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKCModelColumnName (modelName):\n",
    "    return 'KC (' + modelName + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpportunityColumnName (modelName):\n",
    "    return 'Opportunity (' + modelName +')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictedErrorColumnName (modelName):\n",
    "    return 'Predicted Error Rate (' + modelName + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_model_name(model_name):\n",
    "    match = re.search(r'\\((.*?)\\)', model_name)\n",
    "    if match is None:\n",
    "        return model_name\n",
    "    else:\n",
    "        return match.group(1)\n",
    "\n",
    "# print(strip_model_name(\"KC (Orignial)\"))\n",
    "# print(strip_model_name(\"Predicted Error Rate (Orignial)\"))\n",
    "# print(strip_model_name(\"Orignial\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_or_inf(value):\n",
    "    if value.lower() in (\"inf\", \"infinity\"):\n",
    "        return float(\"inf\")  # Represent infinity\n",
    "    return int(value)  # Otherwise, convert to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_str_to_float(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_filename(filename):\n",
    "    # Define invalid characters based on cross-platform rules\n",
    "    invalid_chars = r'[\\\\/:*?\"<>|]'\n",
    "    # Replace invalid characters with an underscore\n",
    "    sanitized = re.sub(invalid_chars, '_', filename)\n",
    "    # Remove leading or trailing spaces and periods\n",
    "    sanitized = sanitized.strip(' .')\n",
    "    #remove space and comma and quotes just in case\n",
    "    sanitized = re.sub(r\"[ ,',\\\"]\", \"_\", sanitized)\n",
    "    return sanitized\n",
    "# filename = \"example:i,n valid|file*name?that\\\"this'.txt\"\n",
    "# safe_filename = sanitize_filename(filename)\n",
    "# print(safe_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect if the model is multi-skilled\n",
    "def multiskilled_detector (df, model):\n",
    "    # Filter rows where the KC (model) column contains '~~'\n",
    "    kc_model = getKCModelColumnName(model)\n",
    "    df[kc_model] = df[kc_model].astype(str)\n",
    "    filtered_df = df[df[kc_model].str.contains('~~', case=False, na=False)]\n",
    "    if filtered_df is None or filtered_df.empty:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# df = pd.read_csv(\"ds76_student_step_All_Data_74_2020_0926_034727.txt\", sep='\\t')\n",
    "# print(multiskilled_detector(df, \"Original\"))\n",
    "# print(multiskilled_detector(df, \"Lasso Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the multi-skilled row into multiple rows\n",
    "#the columns to be repeated: Anon Student Id, First Attempt,  Predicted Error Rate (model)\n",
    "#the columns to be changed: KC (model), Opportunity (model)\n",
    "def multiskilled_converter (df, model):\n",
    "    # Split  KC (model) and Opportunity (model) columns by ~~\n",
    "    model_col_name = getKCModelColumnName(model)\n",
    "    opportunity_col_name = getOpportunityColumnName(model)\n",
    "    \n",
    "    df[model_col_name] = df[model_col_name].str.split('~~')\n",
    "    df[opportunity_col_name] = df[opportunity_col_name].astype(str)\n",
    "    df[opportunity_col_name] = df[opportunity_col_name].str.split('~~')\n",
    "    predicted_error_rate_col_name = 'Predicted Error Rate (' + model + ')'\n",
    "    anon_student_id_col_name = 'Anon Student Id'\n",
    "    first_attempt_col_name = 'First Attempt'\n",
    "    \n",
    "    #delete the rows that opportunity is none or model is none\n",
    "    df = df.dropna(subset=[opportunity_col_name])\n",
    "    df = df.dropna(subset=[model_col_name])\n",
    "    \n",
    "    df_expanded = pd.DataFrame({\n",
    "        anon_student_id_col_name: df[anon_student_id_col_name].repeat(df[model_col_name].str.len()),   # Repeat the anon_student_id based on the length of each list\n",
    "        first_attempt_col_name: df[first_attempt_col_name].repeat(df[model_col_name].str.len()),  \n",
    "        predicted_error_rate_col_name: df[predicted_error_rate_col_name].repeat(df[model_col_name].str.len()), \n",
    "        model_col_name: [item for sublist in df[model_col_name] for item in sublist],  # Flatten the lists of values\n",
    "        opportunity_col_name: [item for sublist in df[opportunity_col_name] for item in sublist]  \n",
    "    }).reset_index(drop=True)\n",
    "    df_expanded[opportunity_col_name] = pd.to_numeric(df_expanded[opportunity_col_name], errors='coerce')\n",
    "    return df_expanded\n",
    "\n",
    "# df = pd.read_csv(\"ds76_student_step_All_Data_74_2020_0926_034727.txt\", sep='\\t')\n",
    "# print(multiskilled_converter (df, \"Lasso Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle the last empty tab, BKT's output has an extra tab in each row except the header row\n",
    "def cleanLastEmptyTabInData(filename, workingDir):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # First line is the header — keep it as-is\n",
    "    header = lines[0].rstrip('\\n')\n",
    "\n",
    "    # Process data rows: remove the last field if it’s empty (caused by trailing tab)\n",
    "    cleaned_rows = []\n",
    "    for line in lines[1:]:\n",
    "        parts = line.rstrip('\\n').split('\\t')\n",
    "        if parts[-1] == '':  # trailing tab led to empty last field\n",
    "            parts = parts[:-1]\n",
    "        cleaned_rows.append('\\t'.join(parts))\n",
    "\n",
    "    # Combine back into one list\n",
    "    cleaned_lines = [header] + cleaned_rows\n",
    "    \n",
    "    filename_only = os.path.basename(filename)\n",
    "    name, ext = os.path.splitext(filename_only)  # name = 'data_file', ext = '.csv'\n",
    "    cleaned_file_name = os.path.join(workingDir, f\"cleaned_file_{name}{ext}\" )\n",
    "\n",
    "    # Write to new file\n",
    "    with open(cleaned_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in cleaned_lines:\n",
    "            f.write(line + '\\n')\n",
    "    return cleaned_file_name\n",
    "\n",
    "# df = pd.read_csv(cleanLastEmptyTabInData(\"Step-values-with-predictions1.txt\", \".\"), sep='\\t')\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up a dataframe: multi-skill conversion and first attempt conversion\n",
    "def clean_df (df, model):\n",
    "    #multiskill conversion\n",
    "    if multiskilled_detector(df, model):\n",
    "        df = multiskilled_converter(df, model)\n",
    "    df['First Attempt Num'] = [1 if x =='correct' else 0 for x in df['First Attempt']]\n",
    "    opp_column_name = getOpportunityColumnName(model)\n",
    "    model_col_name = getKCModelColumnName(model)\n",
    "    #delete the rows that opportunity is none or not number\n",
    "    # Step 1: Drop rows where opp is NaN or None\n",
    "    df = df.dropna(subset=[opp_column_name])\n",
    "    df = df.dropna(subset=[model_col_name])\n",
    "    # Step 2: Drop rows where opp is not a number\n",
    "    df = df[pd.to_numeric(df[opp_column_name], errors='coerce').notna()]\n",
    "    return df\n",
    "# #df = pd.read_csv(\"ds1_student_step_All_Data_1_2025_0714_175413.txt\", sep='\\t')\n",
    "# df = pd.read_csv(\"Step-values-with-predictions.txt\", sep='\\t')\n",
    "# primary_model = \"decomp\"\n",
    "# #check if model is multi-skilled and convert first attempt to 0/1 and delete rows that are non-numeric in opp column\n",
    "# df = clean_df(df, primary_model)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_thumb_prints_to_html(file_path, thumb_print_html):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.readlines()\n",
    "    # Locate the `</body>` tag and insert the text before it\n",
    "    for i in range(len(content)):\n",
    "        if content[i].strip() == \"</body>\":\n",
    "            content.insert(i, f\"\\n{thumb_print_html}\\n\") \n",
    "            break\n",
    "\n",
    "    # Write the modified content back to the file\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.writelines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chart_parts(html_content, chart_id):\n",
    "    \"\"\"Extract and rename the div and script for unique chart embedding.\"\"\"\n",
    "    # Change the div id\n",
    "    html_content = re.sub(r'id=\"vis\"', f'id=\"{chart_id}\"', html_content)\n",
    "\n",
    "    # Change the embed call to use the new id\n",
    "    html_content = re.sub(r'vegaEmbed\\(\"#vis\"', f'vegaEmbed(\"#{chart_id}\"', html_content)\n",
    "\n",
    "    # Extract <body> content only\n",
    "    body_start = html_content.find('<body>') + len('<body>')\n",
    "    body_end = html_content.find('</body>')\n",
    "    body_content = html_content[body_start:body_end].strip()\n",
    "\n",
    "    return body_content\n",
    "# Example usage:\n",
    "# with open(\"main_graph.html\", 'r', encoding='utf-8') as f1:\n",
    "#         html = f1.read()\n",
    "# print(extract_chart_parts(html, \"vis1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_main_chart_html(main_html_file):\n",
    "    #process the main chart\n",
    "    with open(main_html_file, 'r', encoding='utf-8') as f:\n",
    "        main_orig_html = f.read()\n",
    "    main_html = extract_chart_parts(main_orig_html, \"all\")\n",
    "    main_html = f'''\n",
    "        <div style=\"margin-bottom: 10px;\">\n",
    "                    {main_html}\n",
    "        </div>'''\n",
    "    return main_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_html(element_file_dict, element_opportunity_cnt_htmls, skill_categories):\n",
    "    combined_html = \"\"\n",
    "    if element_file_dict is not None and len(element_file_dict) > 0 and len(skill_categories) > 0:\n",
    "        for category, elements in skill_categories.items():\n",
    "            if elements is not None and len(elements) > 0:\n",
    "                category_element_file_dict = {k: element_file_dict[k] for k in elements if k in element_file_dict}\n",
    "                category_thrumbprint_html = no_category_html(category_element_file_dict, element_opportunity_cnt_htmls)\n",
    "                formatted_category = category.replace('_', ' ').title()\n",
    "                combined_html = f'''{combined_html}\\n\n",
    "                    <div style=\"clear:left\">\n",
    "                        <hr>\n",
    "                    </div>\n",
    "                    <div id=\"perCategoryThumbs_{category}\" style=\"clear:left\">\n",
    "                        <p class=\"classified_label\">\n",
    "                        <span style=\"font-weight: bold; font-size: 14px; font-family: Arial, sans-serif;\">\n",
    "                        {formatted_category}</span></p>\n",
    "                    </div>\n",
    "                    {category_thrumbprint_html}\\n\n",
    "                '''\n",
    "    return combined_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_category_html(element_file_dict, element_opportunity_cnt_htmls):\n",
    "    if element_file_dict is None or len(element_file_dict) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        html = ''\n",
    "        for i, (key, value) in enumerate(element_file_dict.items()):\n",
    "            #the element html\n",
    "            element_file = os.path.join(working_dir, f\"{value}.html\")\n",
    "            with open(element_file, 'r', encoding='utf-8') as f:\n",
    "                element_html = f.read()\n",
    "            element_chart = extract_chart_parts(element_html, f\"{value}\")   \n",
    "            element_html = element_opportunity_cnt_htmls[key]\n",
    "            html = f'''{html}\\n\n",
    "                    <div style=\"margin-bottom: 10px;\">\\n\n",
    "                    {element_chart}\\n\n",
    "                    {element_html}\\n\n",
    "                    </div>'''\n",
    "        return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get the first level of aggregation: either by KC or student + opp\n",
    "#allowed value for group_by is Knowledge Components or Students\n",
    "#aggregate_measures, allowed values: \"Error Rate\", \"Assistance Score\", \"Number of Incorrects\", \"Number of Hints\", \"Step Duration\", \"Correct Step Duration\", \"Error Step Duration\"\n",
    "#error_bar, allowed values: \"No Error Bars\", \"Standard Deviation\", \"Standard Error\"\n",
    "def get_df_kc_opp_aggr(df, model, group_by = 'Knowledge Components', aggregate_meatures = \"Error Rate\", error_bar = \"No Error Bars\"):\n",
    "    kc = getKCModelColumnName(model)\n",
    "    kc_opportunity = getOpportunityColumnName(model)\n",
    "    kc_predicted_error_rate = getPredictedErrorColumnName(model)\n",
    "    group_by_column = \"\"\n",
    "    if group_by.lower() == 'students':\n",
    "        group_by_column = 'Anon Student Id'\n",
    "    else:\n",
    "        group_by_column = kc\n",
    "    #get avg of predicted error rate and avg of first attempt for each \"kc + opp\"\n",
    "    if aggregate_meatures == \"Assistance Score\":\n",
    "        df[\"Assistance Score\"] = df[\"Incorrects\"] + df[\"Hints\"]\n",
    "    elif aggregate_meatures == \"Step Duration\":\n",
    "        df['Step Duration (sec)'] = pd.to_numeric(df['Step Duration (sec)'], errors='coerce')\n",
    "        df = df[df['Step Duration (sec)'].notna()]\n",
    "    elif aggregate_meatures == \"Correct Step Duration\":\n",
    "        df['Correct Step Duration (sec)'] = pd.to_numeric(df['Correct Step Duration (sec)'], errors='coerce')\n",
    "        df = df[df['Correct Step Duration (sec)'].notna()]\n",
    "    elif aggregate_meatures == \"Error Step Duration\":\n",
    "        df['Error Step Duration (sec)'] = pd.to_numeric(df['Error Step Duration (sec)'], errors='coerce')\n",
    "        df = df[df['Error Step Duration (sec)'].notna()]\n",
    "    grouped = df.groupby([group_by_column, kc_opportunity])\n",
    "    \n",
    "    if aggregate_meatures == \"Assistance Score\":\n",
    "        if error_bar == \"No Error Bars\":\n",
    "            errrate = grouped[['Assistance Score']].agg(np.mean)\n",
    "        elif error_bar == \"Standard Deviation\":\n",
    "            errrate = grouped[['Assistance Score']].agg(['mean', 'std'])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Assistance Score_mean': 'Assistance Score', 'Assistance Score_std': 'Error Bar'})\n",
    "        elif error_bar == \"Standard Error\":\n",
    "            errrate = grouped[['Assistance Score']].agg(['mean', lambda x: x.std(ddof=1) / np.sqrt(len(x))])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Assistance Score_mean': 'Assistance Score', 'Assistance Score_<lambda_0>': 'Error Bar'})\n",
    "        errrate = errrate.reset_index()\n",
    "    elif aggregate_meatures == \"Number of Incorrects\":\n",
    "        if error_bar == \"No Error Bars\":\n",
    "            errrate = grouped[['Incorrects']].agg(np.mean)\n",
    "        elif error_bar == \"Standard Deviation\":\n",
    "            errrate = grouped[['Incorrects']].agg(['mean', 'std'])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Incorrects_mean': 'Incorrects', 'Incorrects_std': 'Error Bar'})\n",
    "        elif error_bar == \"Standard Error\":\n",
    "            errrate = grouped[['Incorrects']].agg(['mean', lambda x: x.std(ddof=1) / np.sqrt(len(x))])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Incorrects_mean': 'Incorrects', 'Incorrects_<lambda_0>': 'Error Bar'})\n",
    "        errrate = errrate.reset_index()\n",
    "    elif aggregate_meatures == \"Number of Hints\":\n",
    "        if error_bar == \"No Error Bars\":\n",
    "            errrate = grouped[['Hints']].agg(np.mean)\n",
    "        elif error_bar == \"Standard Deviation\":\n",
    "            errrate = grouped[['Hints']].agg(['mean', 'std'])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Hints_mean': 'Hints', 'Hints_std': 'Error Bar'})\n",
    "        elif error_bar == \"Standard Error\":\n",
    "            errrate = grouped[['Hints']].agg(['mean', lambda x: x.std(ddof=1) / np.sqrt(len(x))])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Hints_mean': 'Hints', 'Hints_<lambda_0>': 'Error Bar'})\n",
    "        errrate = errrate.reset_index()\n",
    "    elif aggregate_meatures == \"Step Duration\":\n",
    "        if error_bar == \"No Error Bars\":\n",
    "            errrate = grouped[['Step Duration (sec)']].agg(np.mean)\n",
    "        elif error_bar == \"Standard Deviation\":\n",
    "            errrate = grouped[['Step Duration (sec)']].agg(['mean', 'std'])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Step Duration (sec)_mean': 'Step Duration (sec)', 'Step Duration (sec)_std': 'Error Bar'})\n",
    "        elif error_bar == \"Standard Error\":\n",
    "            errrate = grouped[['Step Duration (sec)']].agg(['mean', lambda x: x.std(ddof=1) / np.sqrt(len(x))])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Step Duration (sec)_mean': 'Step Duration (sec)', 'Step Duration (sec)_<lambda_0>': 'Error Bar'})\n",
    "        errrate = errrate.reset_index()\n",
    "    elif aggregate_meatures == \"Correct Step Duration\":\n",
    "        if error_bar == \"No Error Bars\":\n",
    "            errrate = grouped[['Correct Step Duration (sec)']].agg(np.mean)\n",
    "        elif error_bar == \"Standard Deviation\":\n",
    "            errrate = grouped[['Correct Step Duration (sec)']].agg(['mean', 'std'])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Correct Step Duration (sec)_mean': 'Correct Step Duration (sec)', 'Correct Step Duration (sec)_std': 'Error Bar'})\n",
    "        elif error_bar == \"Standard Error\":\n",
    "            errrate = grouped[['Correct Step Duration (sec)']].agg(['mean', lambda x: x.std(ddof=1) / np.sqrt(len(x))])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Correct Step Duration (sec)_mean': 'Correct Step Duration (sec)', 'Correct Step Duration (sec)_<lambda_0>': 'Error Bar'})\n",
    "        errrate = errrate.reset_index()\n",
    "    elif aggregate_meatures == \"Error Step Duration\":\n",
    "        if error_bar == \"No Error Bars\":\n",
    "            errrate = grouped[['Error Step Duration (sec)']].agg(np.mean)\n",
    "        elif error_bar == \"Standard Deviation\":\n",
    "            errrate = grouped[['Error Step Duration (sec)']].agg(['mean', 'std'])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Error Step Duration (sec)_mean': 'Error Step Duration (sec)', 'Error Step Duration (sec)_std': 'Error Bar'})\n",
    "        elif error_bar == \"Standard Error\":\n",
    "            errrate = grouped[['Error Step Duration (sec)']].agg(['mean', lambda x: x.std(ddof=1) / np.sqrt(len(x))])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'Error Step Duration (sec)_mean': 'Error Step Duration (sec)', 'Error Step Duration (sec)_<lambda_0>': 'Error Bar'})\n",
    "        errrate = errrate.reset_index()\n",
    "    else:\n",
    "        if error_bar == \"No Error Bars\":\n",
    "            errrate = grouped[['First Attempt Num', kc_predicted_error_rate]].agg(np.mean)\n",
    "        elif error_bar == \"Standard Deviation\":\n",
    "            errrate = grouped[['First Attempt Num', kc_predicted_error_rate]].agg(['mean', 'std'])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'First Attempt Num_mean': 'First Attempt Num', 'First Attempt Num_std': 'Error Bar',\n",
    "                                              kc_predicted_error_rate + \"_mean\":kc_predicted_error_rate,\n",
    "                                              kc_predicted_error_rate + \"_std\":'Predicted Error Bar',\n",
    "                                             })\n",
    "        elif error_bar == \"Standard Error\":\n",
    "            errrate = grouped[['First Attempt Num', kc_predicted_error_rate]].agg(['mean', lambda x: x.std(ddof=1) / np.sqrt(len(x))])\n",
    "            errrate.columns = ['_'.join(col).strip() for col in errrate.columns.values]\n",
    "            errrate = errrate.rename(columns={'First Attempt Num_mean': 'First Attempt Num', 'First Attempt Num_<lambda_0>': 'Error Bar',\n",
    "                                              kc_predicted_error_rate + \"_mean\":kc_predicted_error_rate,\n",
    "                                              kc_predicted_error_rate + \"_<lambda_0>\":'Predicted Error Bar',\n",
    "                                             })\n",
    "        errrate = errrate.reset_index()\n",
    "        errrate['Error Rate'] = 1 - errrate['First Attempt Num']\n",
    "    #get count for each \"kc + opp\"\n",
    "    counts = grouped.size()\n",
    "    counts = counts.reset_index()\n",
    "    counts = counts.rename(columns={0: 'Count'})\n",
    "    #add count to errrate\n",
    "    errrate['Count'] = counts['Count']\n",
    "    return errrate\n",
    "\n",
    "# df = pd.read_csv(\"ds76_student_step_All_Data_74_2020_0926_034727.txt\", sep='\\t')\n",
    "# df['First Attempt Num'] = [1 if x =='correct' else 0 for x in df['First Attempt']]\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Rate\", 'No Error Bars'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Rate\", 'Standard Deviation'))\n",
    "# print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Rate\", 'Standard Error'))\n",
    "\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Assistance Score\", 'No Error Bars'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Assistance Score\", 'Standard Deviation'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Assistance Score\", 'Standard Error'))\n",
    "\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Incorrects\", 'No Error Bars'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Incorrects\", 'Standard Deviation'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Incorrects\", 'Standard Error'))\n",
    "\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Hints\", 'No Error Bars'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Hints\", 'Standard Deviation'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Hints\", 'Standard Error'))\n",
    "\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Step Duration\", 'No Error Bars'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Step Duration\", 'Standard Deviation'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Step Duration\", 'Standard Error'))\n",
    "\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Correct Step Duration\", 'No Error Bars'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Correct Step Duration\", 'Standard Deviation'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Correct Step Duration\", 'Standard Error'))\n",
    "\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Step Duration\", 'No Error Bars'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Step Duration\", 'Standard Deviation'))\n",
    "#print(get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Step Duration\", 'Standard Error'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the second level of aggregation: by KC\n",
    "#input df should have these columns: same as the df returned from get_df_kc_opp_aggr\n",
    "#column_to_average:\"Error Rate\", \"Predicted Error Rate\", \"Assistance Score\", \"Number of Incorrects\", \"Number of Hints\", \"Step Duration\", \"Correct Step Duration\", \"Error Step Duration\"\n",
    "#error_bar, allowed values: \"No Error Bars\", \"Standard Deviation\", \"Standard Error\"\n",
    "def get_df_opp_aggr(df, model, column_to_average = \"Error Rate\", error_bar = \"No Error Bars\"):\n",
    "    kc = getKCModelColumnName(model)\n",
    "    kc_opportunity = getOpportunityColumnName(model)\n",
    "    kc_predicted_error_rate = getPredictedErrorColumnName(model)\n",
    "    if column_to_average == \"Predicted Error Rate\":\n",
    "        column_to_average = column_to_average + \" (\" + model +\")\"\n",
    "    elif column_to_average == \"Number of Incorrects\":\n",
    "        column_to_average =\"Incorrects\"\n",
    "    elif column_to_average == \"Number of Hints\":\n",
    "        column_to_average =\"Hints\"\n",
    "    elif column_to_average == \"Step Duration\":\n",
    "        column_to_average =\"Step Duration (sec)\"\n",
    "    elif column_to_average == \"Correct Step Duration\":\n",
    "        column_to_average =\"Correct Step Duration (sec)\"\n",
    "    elif column_to_average == \"Error Step Duration\":\n",
    "        column_to_average =\"Error Step Duration (sec)\"\n",
    "    \n",
    "    #aggregate for opp    \n",
    "    grouped = df.groupby([kc_opportunity])\n",
    "    if error_bar == \"No Error Bars\":\n",
    "        aggr_df_by_opportunity = grouped[[column_to_average]].agg(np.mean)\n",
    "    elif error_bar == \"Standard Deviation\":\n",
    "            aggr_df_by_opportunity = grouped[[column_to_average]].agg(['mean', 'std'])\n",
    "            aggr_df_by_opportunity.columns = ['_'.join(col).strip() for col in aggr_df_by_opportunity.columns.values]\n",
    "            if \"Predicted Error Rate\" in column_to_average:\n",
    "                aggr_df_by_opportunity = aggr_df_by_opportunity.rename(columns={column_to_average + '_mean': column_to_average, \n",
    "                                                             column_to_average +'_std': 'Predicted Error Bar' })\n",
    "            else:\n",
    "                aggr_df_by_opportunity = aggr_df_by_opportunity.rename(columns={column_to_average + '_mean': column_to_average, \n",
    "                                                             column_to_average +'_std': 'Error Bar' })\n",
    "    elif error_bar == \"Standard Error\":\n",
    "            aggr_df_by_opportunity = grouped[[column_to_average]].agg(['mean', lambda x: x.std(ddof=1) / np.sqrt(len(x))])\n",
    "            aggr_df_by_opportunity.columns = ['_'.join(col).strip() for col in aggr_df_by_opportunity.columns.values]\n",
    "            if \"Predicted Error Rate\"  in column_to_average:\n",
    "                aggr_df_by_opportunity = aggr_df_by_opportunity.rename(columns={column_to_average + '_mean': column_to_average, \n",
    "                                                                            column_to_average + '_<lambda_0>': 'Predicted Error Bar'})\n",
    "            else:\n",
    "                aggr_df_by_opportunity = aggr_df_by_opportunity.rename(columns={column_to_average + '_mean': column_to_average, \n",
    "                                                                            column_to_average + '_<lambda_0>': 'Error Bar'})\n",
    "    aggr_df_by_opportunity = aggr_df_by_opportunity.reset_index()\n",
    "    #get total count for each opp\n",
    "    totcounts = grouped['Count'].sum().reset_index()\n",
    "    #combine the total count\n",
    "    aggr_df_by_opportunity['Count'] = totcounts['Count']\n",
    "    return aggr_df_by_opportunity\n",
    "\n",
    "# #for test\n",
    "# df = pd.read_csv(\"ds76_student_step_All_Data_74_2020_0926_034727.txt\", sep='\\t')\n",
    "# group_by = \"Knowledge Components\"\n",
    "# #group_by = \"Students\"\n",
    "# model = 'Original'\n",
    "# df = clean_df(df, model)\n",
    "\n",
    "# #test error rate without error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"No Error Bars\")\n",
    "# print(df_aggr)\n",
    "# print(get_df_opp_aggr(df_aggr, \"Original\", column_to_average = \"Error Rate\", error_bar = \"No Error Bars\"))\n",
    "\n",
    "#test error rate with standard error\n",
    "#df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"No Error Bars\")\n",
    "#print(df_aggr)\n",
    "#print(get_df_opp_aggr(df_aggr, \"Original\", column_to_average = \"Error Rate\", error_bar = \"Standard Deviation\"))\n",
    "\n",
    "#test predicted error rate with standard error\n",
    "#df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"No Error Bars\")\n",
    "#print(df_aggr)\n",
    "#print(get_df_opp_aggr(df_aggr, \"Original\", column_to_average = \"Predicted Error Rate\", error_bar = \"Standard Deviation\"))\n",
    "\n",
    "#test assistance score with standard error\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Assistance Score\", 'Standard Error')\n",
    "#print(df_aggr)\n",
    "#print(get_df_opp_aggr(df_aggr, \"Original\", column_to_average = \"Assistance Score\", error_bar = \"Standard Deviation\"))\n",
    "\n",
    "#test assistance score with standard error\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Step Duration\", 'Standard Error')\n",
    "#print(df_aggr)\n",
    "#print(get_df_opp_aggr(df_aggr, \"Original\", column_to_average = \"Error Step Duration\", error_bar = \"Standard Deviation\"))\n",
    "\n",
    "#test assistance score with standard error\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Incorrects\", 'Standard Error')\n",
    "#print(df_aggr)\n",
    "#print(get_df_opp_aggr(df_aggr, \"Original\", column_to_average = \"Number of Incorrects\", error_bar = \"Standard Deviation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw learning curve\n",
    "#df should have these columns: Opportunity (model), \"Error Rate\" or \"Predicted Error Rate (Model)\" or Assistance Score\n",
    "#or \"Incorrects\" or \"Hints\" or \"Step Duration (sec)\" or \"Correct Step Duration (sec)\" or \"Error Step Duration (sec)\" and Count\n",
    "def draw_error_rate_line (df, \n",
    "                          model, \n",
    "                          y_axis, #specfy which column to use for y-axis: \"Error Rate\", \"Predicted Error Rate\", \"Assistance Score\", \"Number of Incorrects\", \"Number of Hints\", \"Step Duration\", \"Correct Step Duration\", \"Error Step Duration\"\n",
    "                          graph_title, #graph's title, leave blank if no title  \n",
    "                          x_axis_title, #x_axis title, leave blank if no title\n",
    "                          y_axis_title, #y-axis title, leave blank if no title\n",
    "                          legend_title, #legend title, leave blank if no title\n",
    "                          width, \n",
    "                          height, \n",
    "                          add_legend = True, #add legend to graph\n",
    "                          point = True, #add point to graph\n",
    "                          error_bar = False): #to add error bar\n",
    "    kc_opportunity = getOpportunityColumnName(model)\n",
    "    x_axis_modified_for_legend = \"\"\n",
    "    y_axis_modified = \"\"\n",
    "    if y_axis == \"Error Rate\":\n",
    "        #y-axis's column name is \"Error Rate\"\n",
    "        y_axis_modified = y_axis\n",
    "        x_axis_modified_for_legend = model + \" (error rate)\"\n",
    "        #change opportunity col name for legend prupose\n",
    "        df[x_axis_modified_for_legend] = df[kc_opportunity]\n",
    "    elif y_axis == \"Predicted Error Rate\":\n",
    "        #y-axis's column name is \"Predicted Error Rate (model)\"\n",
    "        y_axis_modified = y_axis + ' (' + model + ')'\n",
    "        x_axis_modified_for_legend = model + \" (predicted error rate)\"\n",
    "        #change opportunity col name for legend prupose\n",
    "        df[x_axis_modified_for_legend] = df[kc_opportunity]\n",
    "    elif y_axis == \"Assistance Score\":\n",
    "        #change assistance score column name \n",
    "        df = df.rename(columns={'Assistance Score': 'Assistance Score Value'})\n",
    "        #use \"Assistance Score Value\" as y-axis column\n",
    "        y_axis_modified = \"Assistance Score Value\"\n",
    "        x_axis_modified_for_legend = \"Assistance Score\"\n",
    "        #change opportunity col name for legend prupose\n",
    "        df[x_axis_modified_for_legend] = df[kc_opportunity]\n",
    "    elif y_axis == \"Number of Incorrects\":\n",
    "        #change column name \n",
    "        df = df.rename(columns={'Incorrects': 'Incorrects Value'})\n",
    "        #use \"Incorrects Value\" as y-axis column\n",
    "        y_axis_modified = \"Incorrects Value\"\n",
    "        x_axis_modified_for_legend = \"Incorrects\"\n",
    "        #change opportunity col name for legend prupose\n",
    "        df[x_axis_modified_for_legend] = df[kc_opportunity]\n",
    "    elif y_axis == \"Number of Hints\":\n",
    "        #change column name \n",
    "        df = df.rename(columns={'Hints': 'Hints Value'})\n",
    "        #use \"Hints Value\" as y-axis column\n",
    "        y_axis_modified = \"Hints Value\"\n",
    "        x_axis_modified_for_legend = \"Hints\"\n",
    "        #change opportunity col name for legend prupose\n",
    "        df[x_axis_modified_for_legend] = df[kc_opportunity]\n",
    "    elif y_axis == \"Step Duration\":\n",
    "        #change column name \n",
    "        df = df.rename(columns={'Step Duration (sec)': 'Step Duration Value'})\n",
    "        #use \"Step Duration Value\" as y-axis column\n",
    "        y_axis_modified = \"Step Duration Value\"\n",
    "        x_axis_modified_for_legend = \"Step Duration\"\n",
    "        #change opportunity col name for legend prupose\n",
    "        df[x_axis_modified_for_legend] = df[kc_opportunity]\n",
    "    elif y_axis == \"Correct Step Duration\":\n",
    "        #change column name \n",
    "        df = df.rename(columns={'Correct Step Duration (sec)': 'Correct Step Duration Value'})\n",
    "        #use \"Step Duration Value\" as y-axis column\n",
    "        y_axis_modified = \"Correct Step Duration Value\"\n",
    "        x_axis_modified_for_legend = \"Correct Step Duration\"\n",
    "        #change opportunity col name for legend prupose\n",
    "        df[x_axis_modified_for_legend] = df[kc_opportunity]\n",
    "    elif y_axis == \"Error Step Duration\":\n",
    "        #change column name \n",
    "        df = df.rename(columns={'Error Step Duration (sec)': 'Error Step Duration Value'})\n",
    "        #use \"Step Duration Value\" as y-axis column\n",
    "        y_axis_modified = \"Error Step Duration Value\"\n",
    "        x_axis_modified_for_legend = \"Error Step Duration\"\n",
    "        #change opportunity col name for legend prupose\n",
    "        df[x_axis_modified_for_legend] = df[kc_opportunity]\n",
    "    \n",
    "    #get the domain_min and domain_max\n",
    "    domain_min = 0\n",
    "    domain_max = df[y_axis_modified].max()\n",
    "    if domain_max <= 1:\n",
    "        domain_max = 1\n",
    "    elif domain_max <= 10 and domain_max > 1:\n",
    "        domain_max = 10\n",
    "    \n",
    "    if add_legend is not None and not add_legend:\n",
    "        error_rate_chart = alt.Chart(df).transform_calculate(\n",
    "            color='\"' + x_axis_modified_for_legend + '\"').mark_line(point=point).encode(\n",
    "            alt.X(x_axis_modified_for_legend, title=x_axis_title), \n",
    "            alt.Y(y_axis_modified, title=y_axis_title, scale=alt.Scale(domain=[domain_min, domain_max])),\n",
    "              color = alt.Color('color:N', legend=None),\n",
    "              tooltip=[alt.Tooltip(kc_opportunity, title=\"Opportunity\"), alt.Tooltip(y_axis_modified, title=y_axis), alt.Tooltip('Count', title=\"Number of Observations\")]\n",
    "            ).properties(\n",
    "                title=graph_title,\n",
    "                width=width,\n",
    "                height=height\n",
    "            )\n",
    "    else:\n",
    "        error_rate_chart = alt.Chart(df).transform_calculate(\n",
    "            color='\"' + x_axis_modified_for_legend + '\"').mark_line(point=point).encode(\n",
    "            alt.X(x_axis_modified_for_legend, title=x_axis_title), \n",
    "            alt.Y(y_axis_modified, title=y_axis_title, scale=alt.Scale(domain=[domain_min, domain_max])),\n",
    "              color = alt.Color('color:N', legend=alt.Legend(title=legend_title, orient='bottom', direction='vertical')),\n",
    "              tooltip=[alt.Tooltip(kc_opportunity, title=\"Opportunity\"), alt.Tooltip(y_axis_modified, title=y_axis), alt.Tooltip('Count', title=\"Number of Observations\")]\n",
    "            ).properties(\n",
    "                title=graph_title,\n",
    "                width=width,\n",
    "                height=height\n",
    "            )\n",
    "    # Define error bars\n",
    "    if error_bar is not None and error_bar == True:\n",
    "        if y_axis == \"Predicted Error Rate\":\n",
    "            error_bars = alt.Chart(df).mark_errorbar(color='black').encode(\n",
    "                x=x_axis_modified_for_legend,\n",
    "                y=y_axis_modified,\n",
    "                yError='Predicted Error Bar')\n",
    "        else:\n",
    "            error_bars = alt.Chart(df).mark_errorbar(color='black').encode(\n",
    "                x=x_axis_modified_for_legend,\n",
    "                y=y_axis_modified,\n",
    "                yError='Error Bar')\n",
    "        error_rate_chart = alt.layer(error_rate_chart, error_bars)\n",
    "    return error_rate_chart\n",
    "\n",
    "# df = pd.read_csv(\"ds76_student_step_All_Data_74_2020_0926_034727.txt\", sep='\\t')\n",
    "# df = clean_df(df, 'Original')\n",
    "\n",
    "# #test error rate, no error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Rate\", \"No Error Bars\")\n",
    "# df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "# print(df_aggr)\n",
    "# #draw error rate with point and legend\n",
    "# error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Error Rate', 'All', 'Opportunity', 'Error Rate', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#draw error rate without point and legend\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Error Rate', 'All', 'Opportunity', 'Error Rate', 'Legend title', 600, 400, add_legend=False, point=False)\n",
    "#draw predicted error rate\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Predicted Error Rate', 'All', 'Opportunity', 'Predicted Error Rate', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "\n",
    "#test error rate and standard deviation or standard error for error bar\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", aggregate_meatures = \"Error Rate\", error_bar =\"Standard Deviation\")\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", aggregate_meatures = \"Error Rate\", error_bar =\"Standard Error\")\n",
    "#df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "#print(df_aggr)\n",
    "#draw error rate with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Error Rate', 'All', 'Opportunity', 'Error Rate', 'Legend title', 600, 400, add_legend=True, point=True, error_bar = True)\n",
    "#draw predicted error rate with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Predicted Error Rate', 'All', 'Opportunity', 'Predicted Error Rate', 'Legend title', 600, 400, add_legend=True, point=True, error_bar = True)\n",
    "\n",
    "#test error and predicted on the same graphic\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Rate\", \"No Error Bars\")\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Rate\", \"Standard Error\")\n",
    "#df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "#print(df_aggr)\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Error Rate', 'All', 'Opportunity', 'Error Rate', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#pred_error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Predicted Error Rate', 'All', 'Opportunity', 'Error Rate', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#final_error_rate_chart = alt.layer(error_rate_graph, pred_error_rate_graph)\n",
    "#final_error_rate_chart\n",
    "#with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Error Rate', 'All', 'Opportunity', '', '', 600, 400, add_legend=True, point=True, error_bar=True)\n",
    "#pred_error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Predicted Error Rate', 'All', 'Opportunity', '', '', 600, 400, add_legend=True, point=True, error_bar=True)\n",
    "#final_error_rate_chart = alt.layer(error_rate_graph, pred_error_rate_graph)\n",
    "#final_error_rate_chart\n",
    "\n",
    "#test assistance score with and without error bar\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Assistance Score\", 'No Error Bars')\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Assistance Score\", 'Standard Deviation')\n",
    "# df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Assistance Score\", 'Standard Error')\n",
    "# df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "#print(df_aggr)\n",
    "#draw assistance score\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Assistance Score', 'All', 'Opportunity', 'Assistance Score', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#draw assistance score with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Assistance Score', 'All', 'Opportunity', 'Assistance Score', 'Legend title', 600, 400, add_legend=True, point=True, error_bar = True)\n",
    "\n",
    "#test incorrects with and without error bar\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Incorrects\", 'No Error Bars')\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Incorrects\", 'Standard Deviation')\n",
    "#df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "#print(df_aggr)\n",
    "#draw incorrects\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Number of Incorrects', 'All', 'Opportunity', 'whatever', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#draw incorrects with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Number of Incorrects', 'All', 'Opportunity', 'Assistance Score', 'Legend title', 600, 400, add_legend=True, point=True, error_bar = True)\n",
    "\n",
    "#test Number of Hints with and without error bar\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Hints\", 'No Error Bars')\n",
    "# df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Number of Hints\", 'Standard Deviation')\n",
    "#df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "#print(df_aggr)\n",
    "#draw Hints\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Number of Hints', 'All', 'Opportunity', 'whatever', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#draw hints with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Number of Hints', 'All', 'Opportunity', 'hints', 'Legend title', 600, 400, add_legend=True, point=True, error_bar = True)\n",
    "\n",
    "#test Step duration with and without error bar\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Step Duration\", 'No Error Bars')\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Step Duration\", 'Standard Error')\n",
    "#df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "#print(df_aggr)\n",
    "#draw step duration\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Step Duration', 'All', 'Opportunity', 'whatever', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#draw step duration with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Step Duration', 'All', 'Opportunity', 'hints', 'Legend title', 600, 400, add_legend=True, point=True, error_bar = True)\n",
    "\n",
    "#test Correct Step Duration with and without error bar\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Correct Step Duration\", 'No Error Bars')\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Correct Step Duration\", 'Standard Error')\n",
    "#df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "#print(df_aggr)\n",
    "#draw correct step duration\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Correct Step Duration', 'All', 'Opportunity', 'whatever', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#draw correct step duration with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Correct Step Duration', 'All', 'Opportunity', 'hints', 'Legend title', 600, 400, add_legend=True, point=True, error_bar = True)\n",
    "\n",
    "#test Error Step Duration with and without error bar\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Step Duration\", 'No Error Bars')\n",
    "#df_aggr = get_df_kc_opp_aggr(df, \"Original\", \"Knowledge Components\", \"Error Step Duration\", 'Standard Error')\n",
    "#df_aggr = df_aggr[df_aggr['KC (Original)'] == 'ALT:CIRCLE-AREA']\n",
    "#print(df_aggr)\n",
    "#draw correct step duration\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Error Step Duration', 'All', 'Opportunity', 'whatever', 'Legend title', 600, 400, add_legend=True, point=True)\n",
    "#draw correct step duration with error bar\n",
    "#error_rate_graph = draw_error_rate_line(df_aggr, 'Original', 'Error Step Duration', 'All', 'Opportunity', 'hints', 'Legend title', 600, 400, add_legend=True, point=True, error_bar = True)\n",
    "\n",
    "#error_rate_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create graph for a model\n",
    "#opp_aggr_df has these columns: KC (Original), Opportunity (Original), First Attempt Num, Predicted Error Rate (Original), Error Rate (or other values depending on line_to_display), Count\n",
    "def create_model_lc_chart(opp_aggr_df, model, \n",
    "                          group_by_type, #Knowledge Components or Students\n",
    "                          line_to_display, #specfy which column to use for y-axis: \"Error Rate\", \"Predicted Error Rate\", \"Error Rate/Predicted Error Rate\", \"Assistance Score\", \"Number of Incorrects\", \"Number of Hints\", \"Step Duration\", \"Correct Step Duration\", \"Error Step Duration\"\n",
    "                          legend_title, #legend title\n",
    "                          width, height,\n",
    "                          add_legend=True, #false to add no legend\n",
    "                          graph_title=None, #graph title\n",
    "                          x_axis_title=None, #x-axis title\n",
    "                          y_axis_title=None, #y-axis title\n",
    "                          point=True,\n",
    "                          error_bar=\"No Error Bars\"): #\"No Error Bars\", \"Standard Deviation\", \"Standard Error\"\n",
    "    #aggregate for opp    \n",
    "    kc_opportunity = getOpportunityColumnName(model)\n",
    "    kc_predicted_error_rate = getPredictedErrorColumnName(model)\n",
    "    return_graphs = []\n",
    "    \n",
    "    add_error_bar = False\n",
    "    if error_bar != \"No Error Bars\":\n",
    "        add_error_bar = True\n",
    "    \n",
    "    if line_to_display == \"Error Rate/Predicted Error Rate\":\n",
    "        df_aggr_by_opportunity = get_df_opp_aggr(opp_aggr_df, model, column_to_average = \"Error Rate\", error_bar = error_bar)\n",
    "        error_rate_chart = draw_error_rate_line (df_aggr_by_opportunity, model, \"Error Rate\", \n",
    "                                             graph_title, x_axis_title, y_axis_title, legend_title, \n",
    "                                             width, height, \n",
    "                                             add_legend=add_legend, point=point, error_bar=add_error_bar)\n",
    "        if error_rate_chart is not None:\n",
    "            return_graphs.append(error_rate_chart)\n",
    "        pred_df_aggr_by_opportunity = get_df_opp_aggr(opp_aggr_df, model, column_to_average = \"Predicted Error Rate\", error_bar = error_bar)\n",
    "        predicted_error_rate_chart = draw_error_rate_line (pred_df_aggr_by_opportunity, model, 'Predicted Error Rate', \n",
    "                                                           graph_title, x_axis_title, y_axis_title, legend_title, \n",
    "                                                           width, height, \n",
    "                                                           add_legend=add_legend, point=point, error_bar=add_error_bar)\n",
    "        if predicted_error_rate_chart is not None:\n",
    "            return_graphs.append(predicted_error_rate_chart)\n",
    "    else:\n",
    "        df_aggr_by_opportunity = get_df_opp_aggr(opp_aggr_df, model, column_to_average = line_to_display, error_bar = error_bar)\n",
    "        error_rate_chart = draw_error_rate_line (df_aggr_by_opportunity, model, line_to_display, \n",
    "                                             graph_title, x_axis_title, y_axis_title, legend_title, \n",
    "                                             width, height, \n",
    "                                             add_legend=add_legend, point=point, error_bar=add_error_bar)\n",
    "        if error_rate_chart is not None:\n",
    "            return_graphs.append(error_rate_chart)\n",
    "    return return_graphs\n",
    "    \n",
    "# df = pd.read_csv(\"ds76_student_step_All_Data_74_2020_0926_034727.txt\", sep='\\t')\n",
    "# group_by = \"Knowledge Components\"\n",
    "# #group_by = \"Students\"\n",
    "# model = 'Original'\n",
    "# df = clean_df(df, model)\n",
    "\n",
    "# #test error rate, no error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"No Error Bars\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Error Rate', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"All Knowledge Component\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"Error Rate\", #y-axis title\n",
    "#                                point=True,\n",
    "#                                error_bar=\"No Error Bars\")\n",
    "\n",
    "# #test error rate, with error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"No Error Bars\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Error Rate', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"All Knowledge Component\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"Error Rate\", #y-axis title\n",
    "#                                point=True,\n",
    "#                                error_bar=\"Standard Deviation\")\n",
    "\n",
    "#test predicted error rate, with error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Predicted Error Rate\", \"Standard Deviation\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Predicted Error Rate', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"All Knowledge Component\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=True,\n",
    "#                                error_bar=\"Standard Error\")\n",
    "\n",
    "#test no legend, no titles, no points\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Predicted Error Rate\", \"Standard Deviation\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Error Rate', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 175, height = 90, \n",
    "#                                add_legend=False,\n",
    "#                                graph_title=\"\", #graph title\n",
    "#                                x_axis_title=\"\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=False)\n",
    "\n",
    "#test error rate and predicted error rate, with error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"Standard Deviation\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Error Rate/Predicted Error Rate', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"All Knowledge Component\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=True,\n",
    "#                                error_bar=\"Standard Deviation\")\n",
    "\n",
    "# #test error rate and predicted error rate, without error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Error Rate/Predicted Error Rate', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"All Knowledge Component\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=True)\n",
    "\n",
    "#test assistance score with error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Assistance Score\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Assistance Score', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"All Knowledge Component\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=True,\n",
    "#                               error_bar=\"Standard Error\")\n",
    "\n",
    "# #test number of incorrects with error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Number of Incorrects\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Number of Incorrects', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"All Knowledge Component\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=True,\n",
    "#                               error_bar=\"Standard Error\")\n",
    "\n",
    "# #test correct step duration with error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Correct Step Duration\")\n",
    "# print(df_aggr)\n",
    "# graphs = create_model_lc_chart(df_aggr, model, group_by, \n",
    "#                                line_to_display = 'Correct Step Duration', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"All Knowledge Component\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=True,\n",
    "#                               error_bar=\"Standard Error\")\n",
    "\n",
    "# final_graph = None\n",
    "# for graph in graphs:\n",
    "#     if final_graph is None:\n",
    "#         final_graph = graph\n",
    "#     else:\n",
    "#         final_graph = alt.layer(final_graph, graph)\n",
    "# final_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create graph for a student or skill\n",
    "#opp_aggr_df has these columns: KC (Original), Opportunity (Original), First Attempt Num, Predicted Error Rate (Original), Error Rate (or other values depending on line_to_display), Count\n",
    "def create_element_lc_chart(opp_aggr_df, model, \n",
    "                            group_by_type, #Knowledge Components or Students\n",
    "                            element, \n",
    "                            line_to_display, #specfy which column to use for y-axis: \"Error Rate\", \"Predicted Error Rate\", \"Error Rate/Predicted Error Rate\", \"Assistance Score\", \"Number of Incorrects\", \"Number of Hints\", \"Step Duration\", \"Correct Step Duration\", \"Error Step Duration\" \n",
    "                            legend_title, #legend title\n",
    "                            width, height, \n",
    "                            add_legend=True, #false to add no legend\n",
    "                            graph_title=None, #graph title\n",
    "                            x_axis_title=None, #x-axis title\n",
    "                            y_axis_title=None, #y-axis title\n",
    "                            point=True,\n",
    "                           error_bar=\"No Error Bars\"): #\"No Error Bars\", \"Standard Deviation\", \"Standard Error\"\n",
    "    student_name = 'Anon Student Id'\n",
    "    kc_name = getKCModelColumnName(model)\n",
    "    kc_opportunity = getOpportunityColumnName(model)\n",
    "    kc_predicted_error_rate = getPredictedErrorColumnName(model)\n",
    "    return_graphs = []\n",
    "    \n",
    "    opp_aggr_df_copied = None\n",
    "    if group_by_type == 'Knowledge Components':\n",
    "        opp_aggr_df_copied = opp_aggr_df[opp_aggr_df[kc_name] == element].copy()\n",
    "    else:\n",
    "        opp_aggr_df_copied = opp_aggr_df[opp_aggr_df[student_name] == element].copy()\n",
    "        \n",
    "    if opp_aggr_df_copied is None or opp_aggr_df_copied.empty:\n",
    "        return None\n",
    "    \n",
    "    add_error_bar = False\n",
    "    if error_bar != \"No Error Bars\":\n",
    "        add_error_bar = True\n",
    "    \n",
    "    if line_to_display == \"Error Rate/Predicted Error Rate\":\n",
    "        error_rate_chart = draw_error_rate_line (opp_aggr_df_copied, model, \"Error Rate\", \n",
    "                                             graph_title, x_axis_title, y_axis_title, legend_title, \n",
    "                                             width, height, \n",
    "                                             add_legend=add_legend, point=point, error_bar=add_error_bar)\n",
    "        if error_rate_chart is not None:\n",
    "            return_graphs.append(error_rate_chart)\n",
    "        pred_df_aggr_by_opportunity = get_df_opp_aggr(opp_aggr_df_copied, model, column_to_average = \"Predicted Error Rate\", error_bar = error_bar)\n",
    "        predicted_error_rate_chart = draw_error_rate_line (pred_df_aggr_by_opportunity, model, 'Predicted Error Rate', \n",
    "                                                           graph_title, x_axis_title, y_axis_title, legend_title, \n",
    "                                                           width, height, \n",
    "                                                           add_legend=add_legend, point=point, error_bar=add_error_bar)\n",
    "        if predicted_error_rate_chart is not None:\n",
    "            return_graphs.append(predicted_error_rate_chart)\n",
    "    else:\n",
    "        error_rate_chart = draw_error_rate_line (opp_aggr_df_copied, model, line_to_display, \n",
    "                                             graph_title, x_axis_title, y_axis_title, legend_title, \n",
    "                                             width, height, \n",
    "                                             add_legend=add_legend, point=point, error_bar=add_error_bar)\n",
    "        if error_rate_chart is not None:\n",
    "            return_graphs.append(error_rate_chart)\n",
    "    return return_graphs\n",
    "\n",
    "# df = pd.read_csv(\"ds76_student_step_All_Data_74_2020_0926_034727.txt\", sep='\\t')\n",
    "# group_by = \"Knowledge Components\"\n",
    "# #group_by = \"Students\"\n",
    "# model = 'Original'\n",
    "# df = clean_df(df, model)\n",
    "\n",
    "# #test error rate, no error bar for 'ALT:PARALLELOGRAM-AREA' or 'Stu_02ee1b3f31a6f6a7f4b8012298b2395e'\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"No Error Bars\")\n",
    "# print(df_aggr)\n",
    "# element = 'ALT:PARALLELOGRAM-AREA'\n",
    "# #element = 'Stu_02ee1b3f31a6f6a7f4b8012298b2395e'\n",
    "# graphs = create_element_lc_chart(df_aggr, model, group_by, element=element,\n",
    "#                                line_to_display = 'Error Rate', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=element, #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"Error Rate\", #y-axis title\n",
    "#                                point=True,\n",
    "#                                error_bar=\"No Error Bars\")\n",
    "\n",
    "# #test error rate, no error bar for 'ALT:PARALLELOGRAM-AREA' or 'Stu_02ee1b3f31a6f6a7f4b8012298b2395e'\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"Standard Error\")\n",
    "# print(df_aggr)\n",
    "# element = 'ALT:PARALLELOGRAM-AREA'\n",
    "# graphs = create_element_lc_chart(df_aggr, model, group_by, element=element,\n",
    "#                                line_to_display = 'Error Rate/Predicted Error Rate', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=element, #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=True,\n",
    "#                                error_bar=\"Standard Error\")\n",
    "\n",
    "#test assistance score with error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Step Duration\", \"Standard Error\")\n",
    "# print(df_aggr)\n",
    "# element = 'ALT:PARALLELOGRAM-AREA'\n",
    "# graphs = create_element_lc_chart(df_aggr, model, group_by,element=element, \n",
    "#                                line_to_display = 'Step Duration', \n",
    "#                                legend_title = \"Legend\", \n",
    "#                                width = 600, height = 400, \n",
    "#                                add_legend=True,\n",
    "#                                graph_title=\"Step Duration\", #graph title\n",
    "#                                x_axis_title=\"Opportunity\", #x-axis title\n",
    "#                                y_axis_title=\"\", #y-axis title\n",
    "#                                point=True,\n",
    "#                               error_bar=\"Standard Error\")\n",
    "\n",
    "# final_graph = None\n",
    "# for graph in graphs:\n",
    "#     if final_graph is None:\n",
    "#         final_graph = graph\n",
    "#     else:\n",
    "#         final_graph = alt.layer(final_graph, graph)\n",
    "# final_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_aggr should have these columns: Count, KC (model), Opportunity (model)\n",
    "#skill_param_dict: {skill_name: gamma column of the skill table}\n",
    "def categorize_lc(df_aggr, model, skill_slope_dict, \n",
    "                  student_threshold = 10, \n",
    "                  opportunity_threshold = 3, \n",
    "                  low_error_threshold = 0.2, \n",
    "                  high_error_threshold = 0.4, \n",
    "                  slope_threshold = 0.001) :\n",
    "    kc_col = getKCModelColumnName(model)\n",
    "    opportunity_col = getOpportunityColumnName(model)\n",
    "    predicted_error_rate_col = getPredictedErrorColumnName(model)\n",
    "    left_over_kcs = df_aggr[kc_col].unique().tolist()\n",
    "    #rid of points that have count < student_threshold: \n",
    "    df_aggr = df_aggr[(df_aggr['Count'] >= student_threshold)]\n",
    "    #too little data\n",
    "    group_kc_counts = df_aggr.groupby(kc_col).size()\n",
    "    too_little_data = group_kc_counts[group_kc_counts < opportunity_threshold].index.tolist()\n",
    "    left_over_kcs = list(set(left_over_kcs) - set(too_little_data))\n",
    "    #low and flat\n",
    "    df_aggr = df_aggr[df_aggr[kc_col].isin(left_over_kcs)]\n",
    "    df_aggr_opp_threshold = df_aggr[(df_aggr[opportunity_col] >= opportunity_threshold)]\n",
    "    group_kc_max = df_aggr_opp_threshold.groupby(kc_col)['Error Rate'].max()\n",
    "    low_flat_data = group_kc_max[group_kc_max < low_error_threshold].index.tolist()\n",
    "    low_flat_data = list(set(low_flat_data) - set(too_little_data))\n",
    "    left_over_kcs = list(set(left_over_kcs) - set(low_flat_data))\n",
    "    #still high\n",
    "    df_left_over_kc = df_aggr[df_aggr[kc_col].isin(left_over_kcs)]\n",
    "    #for each kc, get the predicted_error at the highest opp\n",
    "    still_high_data = df_left_over_kc.loc[df_left_over_kc.groupby(kc_col)[opportunity_col].idxmax(), [kc_col, 'Error Rate']]\n",
    "    still_high_data = still_high_data[(still_high_data['Error Rate'] >= high_error_threshold)]\n",
    "    still_high_data = still_high_data[kc_col].tolist()\n",
    "    left_over_kcs = list(set(left_over_kcs) - set(still_high_data))\n",
    "    #no learning\n",
    "    no_learning_data = []\n",
    "    for kc in left_over_kcs:\n",
    "        if kc in skill_slope_dict and skill_slope_dict[kc] <= slope_threshold:\n",
    "            no_learning_data.append(kc)\n",
    "    good_data = list(set(left_over_kcs) - set(no_learning_data))\n",
    "    return {\"too_little_data\":too_little_data, \n",
    "           \"low_flat\":low_flat_data,\n",
    "           \"still_high\":still_high_data,\n",
    "           \"no_learning\":no_learning_data,\n",
    "           \"good\":good_data}\n",
    "    \n",
    "    \n",
    "# primary_df = pd.read_csv(\"ds76_student_step_All_Data_74_2020_0926_034727.txt\", sep='\\t')\n",
    "# primary_model = \"Original\"\n",
    "# primary_df = clean_df(primary_df, primary_model)\n",
    "# #get aggregation of kc/student and opp: count, mean of prediction and error\n",
    "# primary_df_aggr = get_df_kc_opp_aggr(primary_df, primary_model, \"kc\")\n",
    "# #primary_df_aggr.to_csv(\"temp.csv\", index=False)\n",
    "# print(primary_df_aggr.columns)\n",
    "# skill_slope_dict = {\"ALT:CIRCLE-AREA\":0.104196940694798,\n",
    "#                    \"ALT:CIRCLE-CIRCUMFERENCE\":0.104196940694798,\n",
    "#                    \"ALT:CIRCLE-DIAMETER\":0.073534474059823,\n",
    "#                    \"ALT:COMPOSE-BY-ADDITION\":0.0}\n",
    "\n",
    "# print(categorize_lc(primary_df_aggr, primary_model, skill_slope_dict,\n",
    "#                   student_threshold = 10, \n",
    "#                   opportunity_threshold = 3, \n",
    "#                   low_error_threshold = 0.2, \n",
    "#                   high_error_threshold = 0.4, \n",
    "#                   slope_threshold = 0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the parameter_xml file and output skill_slope_dict\n",
    "#paramter_xml is generated by afm related workflow component\n",
    "def get_skill_slope_dict_from_xml(parameter_xml_filename):\n",
    "    skill_slope_dict = {}\n",
    "    # Load and parse the XML file\n",
    "    tree = ET.parse(parameter_xml_filename)  # Replace with your actual file path\n",
    "    root = tree.getroot()\n",
    "    for elem in root:\n",
    "        is_skill_elem = False\n",
    "        for subelem in elem:\n",
    "            if subelem.tag == \"type\" and subelem.text == \"Skill\":\n",
    "                is_skill_elem = True\n",
    "                break\n",
    "        if is_skill_elem:\n",
    "            skill_name = None\n",
    "            skill_slope = None\n",
    "            for subelem in elem:\n",
    "                if subelem.tag == \"name\":\n",
    "                    skill_name = subelem.text\n",
    "                if subelem.tag == \"slope\":\n",
    "                    skill_slope = subelem.text\n",
    "            skill_slope = safe_str_to_float(skill_slope)\n",
    "            if skill_name is not None and skill_slope is not None:\n",
    "                skill_slope_dict[skill_name] = skill_slope\n",
    "    return skill_slope_dict\n",
    "#print(get_skill_slope_dict_from_xml(\"Parameters.xml\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse DS model value export and output skill_slope_dict\n",
    "#model_values is generated by DS model value export\n",
    "def get_skill_slope_dict_from_ds_export(model_values_filename):\n",
    "    skill_slope_dict = {}\n",
    "    with open(model_values_filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    extracting = False\n",
    "    extracted_lines = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"KC Values for\"):\n",
    "            extracting = True\n",
    "            continue\n",
    "        if line.startswith(\"Student Values for\"):\n",
    "            extracting = False\n",
    "            break\n",
    "        if extracting:\n",
    "            extracted_lines.append(line.strip())\n",
    "    for line in extracted_lines:\n",
    "        if line.startswith(\"KC Name\") and line.strip() != \"\":\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) == 6:\n",
    "            slope = safe_str_to_float(parts[5])\n",
    "            if slope is not None:\n",
    "                skill_slope_dict[parts[0]] = slope\n",
    "    return skill_slope_dict\n",
    "    \n",
    "#print(get_skill_slope_dict_from_ds_export(\"ds76_afm_kcm472_2025_0225_183654.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_opportunity_html_table(df_opportunity_count):\n",
    "    max_per_row = 20  # how many data points per row set\n",
    "\n",
    "    rows_html = []\n",
    "    for i in range(0, len(df_opportunity_count), max_per_row):\n",
    "        chunk = df_opportunity_count.iloc[i:i+max_per_row]\n",
    "\n",
    "        header_cells = \"\".join(\n",
    "            f'<td class=\"data-cell\">{opp}</td>' for opp in chunk[\"Opportunity\"]\n",
    "        )\n",
    "        count_cells = \"\".join(\n",
    "            f'<td class=\"data-cell\">{cnt}</td>' for cnt in chunk[\"Count\"]\n",
    "        )\n",
    "\n",
    "        rows_html.append(f\"\"\"\n",
    "            <tr>\n",
    "                <td class=\"label-cell\"><b>Opportunity Number</b></td>\n",
    "                {header_cells}\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td class=\"label-cell\"><b>Number of Observations</b></td>\n",
    "                {count_cells}\n",
    "            </tr>\n",
    "        \"\"\")\n",
    "\n",
    "    # Full HTML with a single table\n",
    "    final_html = f\"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif; font-size: 10px; text-align: left; margin-top: 0px; margin-bottom: 50px;\">\n",
    "      <table class=\"styled-table\">\n",
    "        {''.join(rows_html)}\n",
    "      </table>\n",
    "    </div>\n",
    "\n",
    "    <style>\n",
    "    .styled-table {{\n",
    "      border-collapse: collapse;\n",
    "      margin: 10px 10px;\n",
    "      font-size: 10px;\n",
    "\n",
    "    }}\n",
    "    .styled-table td {{\n",
    "      border: 1px solid #000;\n",
    "      padding: 4px 5px;\n",
    "      border-left: none;\n",
    "      border-right: none;\n",
    "      text-align: center;\n",
    "    }}\n",
    "    .label-cell {{\n",
    "      background-color: #f9f9f9;\n",
    "    }}\n",
    "    .data-cell:nth-child(even) {{\n",
    "      background-color: #f2f8ff; /* light blue shading */\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    return final_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hchen\\anaconda3\\envs\\36_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (29) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#test on command line\n",
    "#C:\\Users\\hchen\\Anaconda3\\envs\\36_env\\python.exe DataShop_LC_in_Altair.py -programDir . -workingDir . -userId hcheng -afmSlopeThreshold 0.001 -categorizeLearningCurve false -errorBar \"No Error Bars\" -highErrorThreshold 40.0 -learningCurveGroupBy \"Knowledge Components\" -learningCurveMetric \"Error Rate\" -lowErrorThreshold 20.0 -opportunityCutOffMax INF -opportunityCutOffMin 0 -opportunityThreshold 3 -primaryModel_nodeIndex 0 -primaryModel_fileIndex 0 -primaryModel \"Predicted Error Rate (Original)\" -secondaryModel_nodeIndex 0 -secondaryModel_fileIndex 0 -secondaryModel \"Predicted Error Rate (Original)\" -showPredictedLearningCurve true -studentThreshold 10 -viewSecondary true -node 0 -fileIndex 0 ds76_student_step_All_Data_74_2020_0926_034727.txt\n",
    "#C:\\Users\\hchen\\Anaconda3\\envs\\36_env\\python.exe DataShop_LC_in_Altair.py -programDir . -workingDir . -userId hcheng -afmSlopeThreshold 0.001 -categorizeLearningCurve false -errorBar \"Standard Error\" -highErrorThreshold 40.0 -learningCurveGroupBy \"Knowledge Components\" -learningCurveMetric \"Assistance Score\" -lowErrorThreshold 20.0 -opportunityCutOffMax INF -opportunityCutOffMin 0 -opportunityThreshold 3 -primaryModel_nodeIndex 0 -primaryModel_fileIndex, 0, -primaryModel \"Predicted Error Rate (Area)\" -secondaryModel_nodeIndex 0 -secondaryModel_fileIndex 0 -secondaryModel \"Predicted Error Rate (Area)\" -showPredictedLearningCurve true -studentThreshold 10 -viewSecondary false -node 0 -fileIndex 0 ds76_student_step_All_Data_74_2020_0926_034727.txt\n",
    "\n",
    "#to enable handling of big datasets\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "#command line\n",
    "command_line = False\n",
    "if command_line:\n",
    "    parser = argparse.ArgumentParser(description='Python program to generate learning curves.')\n",
    "    parser.add_argument('-programDir', type=str, help='the component program directory')\n",
    "    parser.add_argument('-workingDir', type=str, help='the component instance working directory')\n",
    "    parser.add_argument('-user', type=str, help='user')\n",
    "    \n",
    "    parser.add_argument('-errorBar', type=str, choices=[\"No Error Bars\", \"Standard Deviation\", \"Standard Error\"], default=\"No Error Bars\", help='error bar type')\n",
    "    parser.add_argument('-learningCurveMetric', type=str, choices=[\"Error Rate\", \"Predicted Error Rate\", \"Assistance Score\", \"Number of Incorrects\", \"Number of Hints\", \"Step Duration\", \"Correct Step Duration\", \"Error Step Duration\"], \n",
    "                        default=\"Error Rate\", help='LC metrics')\n",
    "    parser.add_argument('-learningCurveGroupBy', type=str, choices=[\"Knowledge Components\", \"Students\"], default=\"Knowledge Components\", help='learning curve type')\n",
    "    \n",
    "    parser.add_argument('-categorizeLearningCurve', type=str, choices=[\"true\", \"false\"], default=\"true\", help='categorize leanring curve')\n",
    "    parser.add_argument(\"-showPredictedLearningCurve\", type=str, choices=[\"true\", \"false\"], default=\"true\", help=\"show predicted Learning Curve\")\n",
    "    parser.add_argument(\"-viewSecondary\", type=str, choices=[\"true\", \"false\"], default=\"true\", help=\"show secondary model\")\n",
    "    \n",
    "    parser.add_argument(\"-primaryModel\", type=str, required=True, help=\"Primary model\")\n",
    "    parser.add_argument(\"-secondaryModel\", type=str,  help=\"Secondary model\")\n",
    "    \n",
    "    parser.add_argument(\"-opportunityCutOffMax\", type=int_or_inf, default=\"INF\", help=\"Opprotunity cut off max\")\n",
    "    parser.add_argument(\"-opportunityCutOffMin\", type=int, default=0, help=\"Opprotunity cut off min\")\n",
    "    \n",
    "    parser.add_argument(\"-studentThreshold\", type=int, default=10, help=\"A number for student threshold, used in LC categorization\")\n",
    "    parser.add_argument(\"-afmSlopeThreshold\", type=float, default=0.001, help=\"A floating-point number for model slope threshold, used in LC categorization\")\n",
    "    parser.add_argument(\"-highErrorThreshold\", type=float, default=40.0, help=\"A floating-point number for high error threshhold, used in LC categorization\")\n",
    "    parser.add_argument(\"-lowErrorThreshold\", type=float, default=20.0, help=\"A floating-point number for low error threshold, used in LC categorization\")\n",
    "    parser.add_argument(\"-opportunityThreshold\", type=int, default=3, help=\"A number for opportunity threshold, used in LC categorization\")\n",
    "    \n",
    "    parser.add_argument(\"-node\", nargs=1, action='append')\n",
    "    parser.add_argument(\"-fileIndex\", nargs=2, action='append')\n",
    "    \n",
    "    args, option_file_index_args = parser.parse_known_args()\n",
    "    #process files\n",
    "    primary_file = \"\"\n",
    "    parameter_file = \"\"\n",
    "    for x in range(len(args.node)):\n",
    "        if (args.node[x][0] == \"0\" and args.fileIndex[x][0] == \"0\"):\n",
    "            primary_file = args.fileIndex[x][1]\n",
    "        if (args.node[x][0] == \"1\" and args.fileIndex[x][0] == \"0\"):\n",
    "            parameter_file = args.fileIndex[x][1]\n",
    "            \n",
    "    working_dir = args.workingDir\n",
    "    program_dir = args.programDir\n",
    "    user = args.user\n",
    "    errorBar = args.errorBar\n",
    "    learningCurveMetric = args.learningCurveMetric\n",
    "    learningCurveType = args.learningCurveGroupBy\n",
    "    \n",
    "    showPredictedLearningCurve = args.showPredictedLearningCurve\n",
    "    if showPredictedLearningCurve.lower() == 'true':\n",
    "        showPredictedLearningCurve = True\n",
    "    else:\n",
    "        showPredictedLearningCurve = False\n",
    "    categorizeLearningCurve = args.categorizeLearningCurve\n",
    "    if categorizeLearningCurve.lower() == 'true':\n",
    "        categorizeLearningCurve = True\n",
    "    else:\n",
    "        categorizeLearningCurve = False\n",
    "    viewSecondary = args.viewSecondary\n",
    "    if viewSecondary.lower() == 'true':\n",
    "        viewSecondary = True\n",
    "    else:\n",
    "        viewSecondary = False\n",
    "        \n",
    "    primaryModel = args.primaryModel\n",
    "    secondaryModel = args.secondaryModel\n",
    "    \n",
    "    opportunityCutOffMax = args.opportunityCutOffMax\n",
    "    opportunityCutOffMin = args.opportunityCutOffMin\n",
    "    \n",
    "    studentThreshold = args.studentThreshold\n",
    "    afmSlopeThreshold = args.afmSlopeThreshold\n",
    "    highErrorThreshold = args.highErrorThreshold\n",
    "    lowErrorThreshold = args.lowErrorThreshold\n",
    "    opportunityThreshold = args.opportunityThreshold\n",
    "    \n",
    "else:\n",
    "    primary_file = \"ds76_student_step_All_Data_74_2020_0926_034727.txt\"\n",
    "    #primary_file = \"Step-values-with-predictions.txt\"\n",
    "    parameter_file = \"parameters.xml\"\n",
    "    #parameter_file = \"ds76_afm_kcm472_2025_0225_183654.txt\"\n",
    "    working_dir = \".\"\n",
    "    program_dir = \".\"\n",
    "    user = \"hcheng\"\n",
    "    \n",
    "    errorBar = \"No Error Bars\"\n",
    "    #errorBar = \"Standard Error\"\n",
    "    #errorBar = \"Standard Deviation\"\n",
    "    \n",
    "    learningCurveMetric = \"Error Rate\"\n",
    "    #learningCurveMetric = \"Assistance Score\"\n",
    "    #learningCurveMetric = \"Step Duration\"\n",
    "    learningCurveType = \"Knowledge Components\"\n",
    "    #learningCurveType = \"Students\"\n",
    "    \n",
    "    #categorizeLearningCurve = True\n",
    "    categorizeLearningCurve = False\n",
    "    showPredictedLearningCurve = True\n",
    "    #showPredictedLearningCurve = Fasle\n",
    "    #viewSecondary = True\n",
    "    viewSecondary = False\n",
    "    \n",
    "    primaryModel = \"Predicted Error Rate (Original)\"\n",
    "    secondaryModel = \"Predicted Error Rate (Lasso Model)\"\n",
    "    \n",
    "    opportunityCutOffMax = float(\"inf\")\n",
    "    #opportunityCutOffMax = 20\n",
    "    opportunityCutOffMin = 0\n",
    "    #opportunityCutOffMin = 10\n",
    "    \n",
    "    studentThreshold = 10\n",
    "    afmSlopeThreshold = 0.001\n",
    "    highErrorThreshold = 40.0\n",
    "    lowErrorThreshold = 20.0\n",
    "    opportunityThreshold = 3\n",
    "\n",
    "if showPredictedLearningCurve and learningCurveMetric == \"Error Rate\":\n",
    "    learningCurveMetric = \"Error Rate/Predicted Error Rate\"\n",
    "if learningCurveType == \"Knowledge Components\":\n",
    "    graph_title=\"All Knowledge Components\"\n",
    "elif learningCurveType == \"Students\":\n",
    "    graph_title=\"All Students\"\n",
    "if learningCurveMetric not in [\"Error Rate\", \"Predicted Error Rate\", \"Error Rate/Predicted Error Rate\"]:\n",
    "    categorizeLearningCurve = False\n",
    "    \n",
    "\n",
    "y_axis_title = \"\"\n",
    "#somehow if not error rate, predited error rate, not need to do the y axis\n",
    "if learningCurveMetric in [\"Error Rate\", \"Predicted Error Rate\", \"Error Rate/Predicted Error Rate\"]:\n",
    "    y_axis_title = \"Error Rate\"\n",
    "else:\n",
    "    y_axis_title = f\"{learningCurveMetric} Value\"\n",
    "#fresh new log file\n",
    "logFile_name = os.path.join(working_dir, \"Datashop_LC_in_Altair.wfl\")\n",
    "logFile = open(logFile_name, \"w\")\n",
    "logFile.close();    \n",
    "\n",
    "    \n",
    "#clean primary data\n",
    "primary_model = strip_model_name(primaryModel)\n",
    "primary_opportunity = getOpportunityColumnName(primary_model)\n",
    "#clean the possible ending empty tab, for example, BKT output\n",
    "primary_file = cleanLastEmptyTabInData(primary_file, working_dir)\n",
    "df = pd.read_csv(primary_file, sep='\\t', low_memory=False)\n",
    "#check if model is multi-skilled and convert first attempt to 0/1 and delete rows that are non-numeric in opp column\n",
    "primary_df = clean_df(df, primary_model)\n",
    "\n",
    "#opportunity cutoff\n",
    "if not math.isinf(opportunityCutOffMax):\n",
    "    primary_df = primary_df[primary_df[primary_opportunity] <= opportunityCutOffMax]\n",
    "if opportunityCutOffMin > 0:\n",
    "    primary_df = primary_df[primary_df[primary_opportunity] >= opportunityCutOffMin]\n",
    "    \n",
    "#unique list of students or skills\n",
    "unique_elements = None\n",
    "if learningCurveType == 'Knowledge Components':\n",
    "    unique_elements = primary_df[getKCModelColumnName(primary_model)].unique().tolist()\n",
    "else:\n",
    "    unique_elements = primary_df['Anon Student Id'].unique().tolist()\n",
    "#get aggregation of kc/student and opp: count, mean of prediction and error or others\n",
    "primary_df_aggr = get_df_kc_opp_aggr(primary_df, primary_model, group_by=learningCurveType, aggregate_meatures=learningCurveMetric, error_bar=errorBar)\n",
    "\n",
    "# #test error rate, no error bar\n",
    "# df_aggr = get_df_kc_opp_aggr(df, model, group_by, \"Error Rate\", \"No Error Bars\")\n",
    "#print(df_aggr)\n",
    "\n",
    "all_graphs = create_model_lc_chart(primary_df_aggr, primary_model, learningCurveType, \n",
    "                               line_to_display = learningCurveMetric, \n",
    "                               legend_title = \"Legend\",\n",
    "                               width = 600, height = 400, \n",
    "                               add_legend=True,\n",
    "                               graph_title=graph_title,\n",
    "                               x_axis_title=\"Opportunities\",\n",
    "                               y_axis_title=y_axis_title,\n",
    "                               error_bar=errorBar\n",
    "                               )\n",
    "\n",
    "df_opportunity_cnt = get_df_opp_aggr(primary_df_aggr, primary_model)\n",
    "opportunity_name = getOpportunityColumnName(primary_model)\n",
    "df_opportunity_cnt = df_opportunity_cnt[[opportunity_name, \"Count\"]]\n",
    "df_opportunity_cnt.rename(columns={opportunity_name: \"Opportunity\"}, inplace=True)\n",
    "all_opportunity_cnt_table = make_opportunity_html_table(df_opportunity_cnt)\n",
    "\n",
    "secondary_model = None\n",
    "secondary_df_aggr = None\n",
    "#viewSecondary\n",
    "if viewSecondary:\n",
    "    secondary_model = strip_model_name(secondaryModel)\n",
    "    secondary_opportunity = getOpportunityColumnName(secondary_model)\n",
    "    #clean secondary data\n",
    "    #check if model is multi-skilled and convert first attempt to 0/1 and delete opp that is non-numeric\n",
    "    secondary_df = clean_df(df, secondary_model)\n",
    "    #opportunity cutoff\n",
    "    if not math.isinf(opportunityCutOffMax):\n",
    "        secondary_df = secondary_df[secondary_df[secondary_opportunity] <= opportunityCutOffMax]\n",
    "    if opportunityCutOffMin > 0:\n",
    "        secondary_df = secondary_df[secondary_df[secondary_opportunity] >= opportunityCutOffMin]\n",
    "    secondary_df_aggr = get_df_kc_opp_aggr(secondary_df, secondary_model, group_by=learningCurveType, aggregate_meatures=learningCurveMetric, error_bar=errorBar)\n",
    "    all_graphs_secondary_model = create_model_lc_chart(secondary_df_aggr, secondary_model, learningCurveType, \n",
    "                               line_to_display = learningCurveMetric, \n",
    "                               legend_title = \"Legend\",\n",
    "                               width = 600, height = 400, \n",
    "                               add_legend=True,\n",
    "                               graph_title=graph_title,\n",
    "                               x_axis_title=\"\",                        \n",
    "                               y_axis_title=\"\",\n",
    "                               error_bar=errorBar\n",
    "                               )\n",
    "    if all_graphs is not None and all_graphs_secondary_model is not None:\n",
    "            all_graphs.extend(all_graphs_secondary_model)\n",
    "    elif all_graphs is None and all_graphs_secondary_model is not None:\n",
    "            all_graphs = all_graphs_secondary_model\n",
    "            \n",
    "main_graph = None\n",
    "for graph in all_graphs:\n",
    "    if graph is not None:\n",
    "        if main_graph is None:\n",
    "            main_graph = graph\n",
    "        else:\n",
    "            main_graph = alt.layer(main_graph, graph)\n",
    "if main_graph is not None:\n",
    "    main_graph.save(os.path.join(working_dir, 'all.html'))\n",
    "\n",
    "\n",
    "#get unique list of skills or students\n",
    "# Combine and remove duplicates\n",
    "unique_elements = list(set(unique_elements))\n",
    "element_safe_filename = {}\n",
    "element_opportunity_cnt_htmls = {}\n",
    "for element in unique_elements:\n",
    "    all_graphs_for_this_element = None\n",
    "    #primary model\n",
    "    graphs_for_this_element = create_element_lc_chart(primary_df_aggr, primary_model, learningCurveType, \n",
    "                                                        element = element,\n",
    "                                                        line_to_display = learningCurveMetric, \n",
    "                                                       legend_title = f'Legend for {element}',\n",
    "                                                       width = 600, height = 400, \n",
    "                                                       add_legend=True,\n",
    "                                                       graph_title=element,\n",
    "                                                      x_axis_title=\"Opportunities\",\n",
    "                                                       y_axis_title=y_axis_title,\n",
    "                                                       error_bar=errorBar)\n",
    "    df_element_opportunity_cnt = None\n",
    "    student_name = 'Anon Student Id'\n",
    "    kc_name = getKCModelColumnName(primary_model)\n",
    "    opportunity_name = getOpportunityColumnName(primary_model)\n",
    "    if learningCurveType == 'Knowledge Components':\n",
    "        df_element_opportunity_cnt = primary_df_aggr[primary_df_aggr[kc_name] == element]\n",
    "    else:\n",
    "        df_element_opportunity_cnt = primary_df_aggr[primary_df_aggr[student_name] == element]\n",
    "    df_element_opportunity_cnt = df_element_opportunity_cnt[[opportunity_name, \"Count\"]]\n",
    "    df_element_opportunity_cnt.rename(columns={opportunity_name: \"Opportunity\"}, inplace=True)\n",
    "    element_opportunity_cnt_table = make_opportunity_html_table(df_element_opportunity_cnt)\n",
    "    element_opportunity_cnt_htmls[element] = element_opportunity_cnt_table\n",
    "    \n",
    "    #if opp_aggr_df_copied is None or opp_aggr_df_copied.empty:\n",
    "    #viewSecondary\n",
    "    if viewSecondary:\n",
    "        graphs_for_this_element_secondary_model = create_element_lc_chart(secondary_df_aggr, secondary_model, learningCurveType, \n",
    "                                                                           element = element,\n",
    "                                                                            line_to_display = learningCurveMetric, \n",
    "                                                                           legend_title = f'Legend for {element}',\n",
    "                                                                           width = 600, height = 400, \n",
    "                                                                           add_legend=True,\n",
    "                                                                           graph_title=element,\n",
    "                                                                              x_axis_title=\"\",\n",
    "                                                                           y_axis_title=\"\",\n",
    "                                                                           error_bar=errorBar)\n",
    "        \n",
    "        if graphs_for_this_element is not None and graphs_for_this_element_secondary_model is not None:\n",
    "            graphs_for_this_element.extend(graphs_for_this_element_secondary_model)\n",
    "        elif graphs_for_this_element is None and graphs_for_this_element_secondary_model is not None:\n",
    "            graphs_for_this_element = graphs_for_this_element_secondary_model\n",
    "        elif graphs_for_this_element is None and graphs_for_this_element_secondary_model is None:\n",
    "            continue\n",
    "    #save this\n",
    "    graph_for_this_element = None\n",
    "    if graphs_for_this_element is not None:\n",
    "        for graph in graphs_for_this_element:\n",
    "            if graph is not None:\n",
    "                if graph_for_this_element is None:\n",
    "                    graph_for_this_element = graph\n",
    "                else:\n",
    "                    graph_for_this_element = alt.layer(graph_for_this_element, graph)\n",
    "    safe_filename = sanitize_filename(str(element))\n",
    "    element_safe_filename[str(element)] = safe_filename\n",
    "    if graph_for_this_element is not None:\n",
    "        graph_for_this_element.save(os.path.join(working_dir, f\"{safe_filename}.html\")) \n",
    "    #add to the dict\n",
    "    if graph_for_this_element is not None:\n",
    "        element_safe_filename[str(element)] = safe_filename\n",
    "        \n",
    "#order\n",
    "element_safe_filename = dict(sorted(element_safe_filename.items()))\n",
    "#print(element_safe_filename)\n",
    "\n",
    "#do categorization\n",
    "skill_categories = None\n",
    "if learningCurveType == 'Knowledge Components' and categorizeLearningCurve:\n",
    "    _, ext = os.path.splitext(parameter_file)\n",
    "    if \"xml\" in ext:\n",
    "        skill_slope_dict = get_skill_slope_dict_from_xml(parameter_file)\n",
    "    else:\n",
    "        skill_slope_dict = get_skill_slope_dict_from_ds_export(parameter_file)\n",
    "    #print(skill_slope_dict)\n",
    "    skill_categories = categorize_lc(primary_df_aggr, primary_model, skill_slope_dict,\n",
    "                      student_threshold = studentThreshold, \n",
    "                      opportunity_threshold = opportunityThreshold, \n",
    "                      low_error_threshold = lowErrorThreshold/100, \n",
    "                      high_error_threshold = highErrorThreshold/100, \n",
    "                      slope_threshold = afmSlopeThreshold)\n",
    "    #print(skill_categories)\n",
    "\n",
    "combined_html_head = '''\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\">\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/vega@5\"></script>\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/vega-lite@5\"></script>\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/vega-embed@6\"></script>\n",
    "    </head>\n",
    "    <body>'''\n",
    "combined_html_tail = '''</body>\n",
    "    </html>'''\n",
    "\n",
    "#write the all_final.html\n",
    "all_html = write_main_chart_html(os.path.join(working_dir, \"all.html\"))\n",
    "if learningCurveType == 'Knowledge Components' and categorizeLearningCurve and skill_categories is not None:\n",
    "    elements_html = category_html(element_safe_filename, element_opportunity_cnt_htmls, skill_categories)\n",
    "else:\n",
    "    elements_html = no_category_html(element_safe_filename, element_opportunity_cnt_htmls)\n",
    "\n",
    "all_combined_html = f'''{combined_html_head}\\n\n",
    "                        {all_html}\\n\n",
    "                        {all_opportunity_cnt_table}\\n\n",
    "                        {elements_html}\\n\n",
    "                        {combined_html_tail}'''\n",
    "with open(os.path.join(working_dir, \"all_final.html\"), 'w', encoding='utf-8') as f:\n",
    "    f.write(all_combined_html)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "36_env",
   "language": "python",
   "name": "36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
