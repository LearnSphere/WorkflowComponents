{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeColumns(x):\n",
    "    choice = x['Choice']\n",
    "    correct_answer =  x['Correct Answer']\n",
    "    correct_answers =  x['Correct Answers']\n",
    "    selections =  x['Selections']\n",
    "    input =  x['Input']\n",
    "    step_name = x['Step Name']\n",
    "    student_response_type = x['Student Response Type']\n",
    "    tutor_response_type = x['Tutor Response Type']\n",
    "    outcome = x['Outcome']\n",
    "    if selections is not None and selections:\n",
    "        input = input.split(\",\")\n",
    "        if (choice in input and correct_answer == 1) or (choice not in input and correct_answer == 0):\n",
    "            x['Outcome'] = 'CORRECT'\n",
    "        else:\n",
    "            x['Outcome'] = 'INCORRECT'\n",
    "        x['Step Name'] = step_name + \"_\" + choice\n",
    "    elif (student_response_type and student_response_type == 'ATTEMPT'\n",
    "         and tutor_response_type and tutor_response_type == 'RESULT'\n",
    "         and step_name and outcome):\n",
    "        x['Event Type'] = 'assess_instruct'\n",
    "    elif (student_response_type and student_response_type == 'HINT_REQUEST'\n",
    "         and tutor_response_type and tutor_response_type == 'HINT_MSG'\n",
    "         and step_name):\n",
    "        x['Event Type'] = 'instruct'    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_file_name = \"\"\n",
    "data_file_name = \"\"\n",
    "command_line_exe = True\n",
    "#test command \n",
    "#Python non_instruction_step_converter.py -dataFile \"ds2846_tx_test.txt\" -mapFile \"ds2846_non_instructional_steps_map.txt\"\n",
    "if command_line_exe:\n",
    "    parser = argparse.ArgumentParser(description='Convert multi-selection steps into multiple steps and adjust scoring')\n",
    "    parser.add_argument('-dataFile', type=str, help='data file containing multi-selection steps', required=True)\n",
    "    parser.add_argument('-mapFile', type=str, help='map file containing mapping information ')\n",
    "    args, option_file_index_args = parser.parse_known_args()\n",
    "    data_file_name = args.dataFile\n",
    "    map_file_name = args.mapFile\n",
    "else:\n",
    "    map_file_name = 'ds2846_non_instructional_steps_map.txt'\n",
    "    data_file_name = 'ds2846_tx_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.read_csv(map_file_name, dtype=str, sep=\"\\t\")\n",
    "new_columns = df_map.columns.tolist()\n",
    "new_columns.extend(['Choice', 'Correct Answer', 'Event Type'])\n",
    "df_map_new = pd.DataFrame(columns=new_columns)\n",
    "for i in range(len(df_map.index)):\n",
    "    #this_row = pd.Series(df_map.iloc[i, :])\n",
    "    this_row = df_map.iloc[i, :]\n",
    "    selections = this_row['Selections'].split(\",\")\n",
    "    answers = this_row['Correct Answers'].split(\",\")\n",
    "    selections_count = len(selections)\n",
    "    for j, selection in enumerate(selections):\n",
    "        new_row = this_row.copy()\n",
    "        new_row['Choice'] = selection\n",
    "        if selection in answers:\n",
    "            new_row['Correct Answer'] = 1\n",
    "        else:\n",
    "            new_row['Correct Answer'] = 0\n",
    "        if j < len(selections) - 1:\n",
    "            new_row['Event Type'] = \"assess\"\n",
    "        else:\n",
    "            new_row['Event Type'] = \"assess_instruct\"\n",
    "        new_row = new_row.to_frame().transpose()\n",
    "        if df_map_new.empty:\n",
    "            df_map_new = new_row\n",
    "        else:\n",
    "            df_map_new = df_map_new.append(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file_name, dtype=str, sep=\"\\t\", encoding = \"ISO-8859-1\")\n",
    "#save the first line headers bc Python adds number to duplicate column names\n",
    "infile = open(data_file_name, 'r')\n",
    "original_headers = infile.readline().strip()\n",
    "original_headers = original_headers + \"\\t\" + \"Event Type\" + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Problem Name', 'Step Name']\n"
     ]
    }
   ],
   "source": [
    "#find the columns that has Level() in names for mapFile. Assuming mapFile and dataFile has the same names\n",
    "level_column_names = []\n",
    "for col in df_map_new.columns:\n",
    "    if 'Level (' in col:\n",
    "        level_column_names.append(col)\n",
    "level_column_names.append('Problem Name')\n",
    "level_column_names.append('Step Name')\n",
    "df_combined = pd.merge( df, df_map_new, left_on=level_column_names, right_on=level_column_names, how='left')\n",
    "df_combined['Selections'] = df_combined['Selections'].fillna(value='')\n",
    "df_combined['Input'] = df_combined['Input'].fillna(value='')\n",
    "df_combined['Step Name'] = df_combined['Step Name'].fillna(value='')\n",
    "df_combined['Student Response Type'] = df_combined['Student Response Type'].fillna(value='')\n",
    "df_combined['Tutor Response Type'] = df_combined['Tutor Response Type'].fillna(value='')\n",
    "df_combined['Outcome'] = df_combined['Outcome'].fillna(value='')\n",
    "df_combined['Input'] = df_combined['Input'].astype(str)\n",
    "df_combined.apply(changeColumns, axis=1)\n",
    "df_combined.drop(['Selections', 'Correct Answers', 'Choice', 'Correct Answer'], axis=1, inplace=True)\n",
    "#make new output file name\n",
    "out_file_name = os.path.splitext(os.path.basename(data_file_name))[0] + \"_converted\" + os.path.splitext(os.path.basename(data_file_name))[1]\n",
    "#write the header\n",
    "out_file = open(out_file_name, \"w\")\n",
    "out_file.write(original_headers)\n",
    "out_file.close()\n",
    "with open(out_file_name, 'a', newline='') as f:\n",
    "    df_combined.to_csv(f, sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
