{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e98b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai.error import APIConnectionError\n",
    "import xlsxwriter\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import re\n",
    "import datetime as dt\n",
    "import operator\n",
    "from collections import Counter\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23edec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logProgressToWfl(progressMsg):\n",
    "    logFile = open(log_file_name, \"a\")\n",
    "    now = dt.datetime.now()\n",
    "    progressPrepend = \"%Progress::\"\n",
    "    logFile.write(progressPrepend + \"@\" + str(now) + \"@\" + progressMsg + \"\\n\");\n",
    "    logFile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8d6907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logToWfl(msg):\n",
    "    logFile = open(log_file_name, \"a\")\n",
    "    now = dt.datetime.now()\n",
    "    logFile.write(str(now) + \": \" + msg + \"\\n\");\n",
    "    logFile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f93a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_malformed_json(json_str):\n",
    "    #first delete anything before [ or {\n",
    "    json_str = json_str.lstrip()\n",
    "    #match = re.search(r'\\[\\s*\\{', json_str)\n",
    "    if not json_str.startswith('{') and not json_str.startswith('['):\n",
    "        match = re.search(r'[\\{\\[]', json_str)\n",
    "        if match is None:\n",
    "            return json_str\n",
    "        json_str = json_str[match.start():]\n",
    "    #if json_str ends with }  ]\n",
    "    if bool(re.search(r'}\\s*\\]\\s*$', json_str)):\n",
    "        return json_str\n",
    "    last_comma_pos = json_str.rfind('},')\n",
    "    if last_comma_pos != -1:\n",
    "        # Truncate the string to remove the last malformed object\n",
    "        json_str = json_str[:last_comma_pos+1] + ']'\n",
    "    return json_str\n",
    "\n",
    "# #test\n",
    "# test_str = ''' JSON\n",
    "# [\n",
    "#   {\n",
    "#     \"Line\": 51,\n",
    "#     \"Error\": \"not specified URL\",\n",
    "#     \"Tutor Response\": \"Is the URL configured to go to the IXL website?\",\n",
    "#     \"Score\": 1,\n",
    "#     \"Rationale\": \"The tutor effectively responds by asking the student to clarify what she is asking and guiding her to self-correct without directly stating that a mistake has been made.\"\n",
    "#   },\n",
    "#   {\n",
    "#     \"Line\": 58,\n",
    "#     \"Error\": \"not assigning students to breakout rooms\",\n",
    "#     \"Tutor Response\": \"If you click on apps and then breakout rooms, you can assign students to rooms by dragging them in. Have you tried that?\",\n",
    "#     \"Score\": 1,\n",
    "#     \"Rationale\": \"The tutor effectively addresses the student's confusion by providing clear instructions and guiding her through the process without directly stating that a mistake has been made.\"\n",
    "#   }\n",
    "# ]\n",
    "# '''\n",
    "\n",
    "# test_str = '''\n",
    "# [\n",
    "#   {\n",
    "#     \"Line\": 51,\n",
    "#     \"Error\": \"not specified URL\",\n",
    "#     \"Tutor Response\": \"Is the URL configured to go to the IXL website?\",\n",
    "#     \"Score\": 1,\n",
    "#     \"Rationale\": \"The tutor effectively responds by asking the student to clarify what she is asking and guiding her to self-correct without directly stating that a mistake has been made.\"\n",
    "#   },\n",
    "#   {\n",
    "#     \"Line\": 58,\n",
    "#     \"Error\": \"not assigning students to breakout rooms\",\n",
    "#     \"Tutor Response\": \"If you click on apps and then breakout rooms, you can assign students to rooms by dragging them in. Have you tried that?\",\n",
    "#     \"Score\": 1,\n",
    "#     \"Rationale\": \"The tut\n",
    "# '''\n",
    "\n",
    "# test_str = '''\n",
    "# junk here\n",
    "# {\"Rationale\": \"The tutor effectively reacted to the student's error by guiding and motivating them to find their own mistake. When the student said \"72 equal to four\", the tutor asked clarifying questions such as \"What do you mean?\" and \"What is 72 times four?\" to help the student think critically about the problem. This approach allows the student to reach the correct answer on their own, promoting their problem-solving skills and building their confidence. Therefore, the tutor receives a score of 1.\", \"Score\": 1}\n",
    "\n",
    "# '''\n",
    "\n",
    "# test_str = '''\n",
    "# Math not found\n",
    "# '''\n",
    "\n",
    "# print(fix_malformed_json(test_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea841318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_response(response_str, json_obj=False):\n",
    "    #response = response_obj['choices'][0]['text'].strip()\n",
    "    #response = response_obj.choices[0].message.content\n",
    "    #response is extracted already in query_open_ai when stream is set to true\n",
    "    if not json_obj:\n",
    "        return response_str\n",
    "    #clean the misformed JSON, happened when max_token is too small, last object can be truncated\n",
    "    response_str = fix_malformed_json(response_str)\n",
    "    df = pd.DataFrame()\n",
    "    try:\n",
    "        # Attempt to load the JSON\n",
    "        parsed = json.loads(response_str)\n",
    "        if isinstance(parsed, list):\n",
    "            for obj in parsed:\n",
    "                new_row = {}\n",
    "                for key, value in obj.items():\n",
    "                    new_row[key] = value\n",
    "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            return df\n",
    "        elif isinstance(parsed, dict):\n",
    "            new_row = {}\n",
    "            for key, value in parsed.items():\n",
    "                new_row[key] = value\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            return df\n",
    "        else:\n",
    "            new_row = {}\n",
    "            new_row['Response'] = response_str\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        new_row = {}\n",
    "        new_row['Response'] = response_str\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        return df\n",
    "\n",
    "# #test\n",
    "# #print(extract_response(\"error not found\", json_obj=True))\n",
    "# test_str = '''[\\n    {\\n        \"Line\": 46,\\n        \"Error\": \"Incorrect statement that 2 can go into 7\",\\n        \"Tutor Response\": \"You can\\'t go into seven evenly. 2, 4, 6, 8.\",\\n        \"Score\": 1,\\n        \"Rationale\": \"The tutor effectively corrects the student\\'s misunderstanding by listing multiples of 2, guiding the student to see the error.\"\\n    },\\n    {\\n        \"Line\": 57,\\n        \"Error\": \"Incorrect statement that 3 can go into 5\",\\n        \"Tutor Response\": \"Three can go into, uh, five. Cannot go into\",\\n        \"Score\": 1,\\n        \"Rationale\": \"The tutor corrects the student by clarifying that 3 cannot go into 5, effectively addressing the mistake.\"\\n    },\\n    {\\n        \"Line\": 65,\\n        \"Error\": \"Incorrect statement about divisibility of 9 into 53\",\\n        \"Tutor Response\": \"So does nine go 53? No, no. Goes 54.\",\\n        \"Score\": 1,\\n        \"Rationale\": \"The tutor effectively points out the correct understanding of divisibility by 9, correcting the student\\'s error.\"\\n    },\\n    {\\n        \"Line\": 85,\\n        \"Error\": \"Incorrect addition of 18 and 5, resulting in 23 instead of 23\",\\n        \"Tutor Response\": \"Five is 23, I think.\",\\n        \"Score\": 0,\\n        \"Rationale\": \"The tutor confirms an incorrect calculation without correction, which does not help the student understand the correct operation.\"\\n    },\\n    {\\n        \"Line\": 90,\\n        \"Error\": \"Incorrect statement that 3 goes into 28 evenly\",\\n        \"Tutor Response\": \"Now three going to 28. I can play right now. 28 even.\",\\n        \"Score\": 0,\\n        \"Rationale\": \"The tutor incorrectly confirms that 3 goes into 28 evenly, reinforcing the student\\'s error instead of correcting it.\"\\n    }\\n]'''\n",
    "# print(extract_response(test_str, json_obj=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2bb5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vtt_to_df(vtt_file):\n",
    "    df = pd.DataFrame(columns=[\"start_time\", \"end_time\", \"text\"])\n",
    "    pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2}\\.\\d{3}) --> (\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\\n(.+)', re.MULTILINE)\n",
    "    with open(vtt_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        matches = pattern.findall(content)\n",
    "        for match in matches:\n",
    "            new_row = {\"start_time\": match[0], \"end_time\": match[1], \"text\": match[2].strip()}\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# #test\n",
    "# transcript_filename = \"drive-download-20250325T133806Z-001/878010494_captions.vtt\"\n",
    "# #transcript_filename = \"A2 Transcript of user 216886 tutor session on 2023-09-25 LS id 4760786.vtt\"\n",
    "# print(vtt_to_df(transcript_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f230384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_column_prompt_text(df, col):\n",
    "    return \"\\n\".join(f\"{i+1} {row}\" for i, row in enumerate(df[col]))\n",
    "\n",
    "# #test\n",
    "# #transcript_filename = \"drive-download-20250325T133806Z-001/878010494_captions.vtt\"\n",
    "# transcript_filename = \"A2 Transcript of user 216886 tutor session on 2023-09-25 LS id 4760786.vtt\"\n",
    "# df = vtt_to_df(transcript_filename)\n",
    "# print(convert_df_column_prompt_text(df, \"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d8dfd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt file should has this: Transcript Start --- --- Transcript End\n",
    "# text before Transcript Start --- is the prompt; text after --- Transcript End is the format prompt\n",
    "class PromptFormatError(Exception):\n",
    "    pass\n",
    "\n",
    "def parse_prompt(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        found_start_prompt = \"Transcript Start ---\" in content\n",
    "        found_format_prompt = \"--- Transcript End\" in content\n",
    "        if not found_start_prompt or not found_format_prompt:\n",
    "            raise PromptFormatError('Prompt file missing \"Transcript Start ---\" or \"--- Transcript End\"')\n",
    "        start_prompt = content.split(\"Transcript Start ---\")[0] + \"Transcript Start ---\\n\"\n",
    "        format_prompt = \"--- Transcript End\" + content.split(\"--- Transcript End\", 1)[1]\n",
    "        return (start_prompt, format_prompt)\n",
    "    \n",
    "# # test\n",
    "# prompt_filename = \"math_error_filter_prompt.txt\"\n",
    "# prompt_start, format_prompt = parse_prompt(prompt_filename)\n",
    "# print(prompt_start)\n",
    "# print(format_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74262ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract csv and get all files with extension vtt\n",
    "def get_files_in_zip(zip_filename, extract_to):\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    allfiles = []\n",
    "    for root, _, files in os.walk(extract_to):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".vtt\") or file.lower().endswith(\".csv\") or file.lower().endswith(\".txt\"):\n",
    "                allfiles.append(os.path.join(root, file))\n",
    "    return allfiles\n",
    "#test\n",
    "#print(get_files_in_zip(\"danielle_vtts.zip\", \"./unzipped_temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56a7f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean a the double // or \\\\ from the file path\n",
    "def clean_filename(filename):\n",
    "    normalized_name = os.path.normpath(filename)\n",
    "    # Remove leading dot and backslash if present\n",
    "    if normalized_name.startswith((\".\\\\\", \"./\")):\n",
    "        normalized_path = normalized_path[2:]\n",
    "    return normalized_name\n",
    "#print(clean_filename(\".//unzipped_files_temp\\\\blah//blah2\\\\878010491_captions.vtt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9908e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_open_ai(prompt, temperature=1, max_tokens=200):\n",
    "    response_obj = openai.Completion.create(engine = \"gpt-3.5-turbo-instruct\", \n",
    "                                            prompt = prompt, \n",
    "                                            temperature = temperature,\n",
    "                                            max_tokens = max_tokens)\n",
    "    response = response_obj['choices'][0]['text'].strip()\n",
    "    return response\n",
    "\n",
    "# #test\n",
    "# openai_api_key = \"your_key\"\n",
    "# openai.api_key = openai_api_key\n",
    "# #prompt_filename = \"math_error_filter_prompt.txt\"\n",
    "# #prompt_filename = \"Plus_math_error_evaluation_prompt_gpt_4o.txt\"\n",
    "# prompt_filename = \"math_error_by_line_prompt_gpt35.txt\"\n",
    "# prompt_start, format_prompt = parse_prompt(prompt_filename)\n",
    "# transcript_filename = \"drive-download-20250325T133806Z-001/878010491_captions.vtt\"\n",
    "# df = vtt_to_df(transcript_filename)\n",
    "# all = convert_df_column_prompt_text(df, \"text\")\n",
    "# prompt = f\"\"\"{prompt_start} {all} {format_prompt}\"\"\"\n",
    "# response = None\n",
    "# try:\n",
    "#     response = query_open_ai(prompt)\n",
    "# except APIConnectionError as e:\n",
    "#     print(f\"API Connection Error: {e}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "# print(response)\n",
    "# print(extract_response(response, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae1d178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename: vtt or csv\n",
    "class FileTypeError(Exception):\n",
    "    pass\n",
    "\n",
    "def evaluation_file(transcript_filename, prompt_filename, cur_file_cnt, all_file_cnt, col=None, \n",
    "                        num_tries=3, temperature=1, max_tokens=200): \n",
    "    #prompt file\n",
    "    prompt_start, format_prompt = parse_prompt(prompt_filename)\n",
    "    #transcript file\n",
    "    file_ext = os.path.splitext(transcript_filename)[1]\n",
    "    all_text = None\n",
    "    if file_ext.lower() == \".csv\":\n",
    "        df = pd.read_csv(transcript_filename)\n",
    "        if col not in df.columns:\n",
    "            raise FileTypeError(\"CSV doesn't have the specified utterence column\")\n",
    "        all_text = convert_df_column_prompt_text(df, col)\n",
    "    elif file_ext.lower() == \".vtt\":\n",
    "        df = vtt_to_df(transcript_filename)\n",
    "        all_text = convert_df_column_prompt_text(df, \"text\")\n",
    "    elif file_ext.lower() == \".txt\":\n",
    "        with open(transcript_filename, 'r', encoding='utf-8') as file:\n",
    "            all_text = file.read()\n",
    "    else:\n",
    "        raise FileTypeError('Transcript file can only be CSV, VTT or TXT')\n",
    "        \n",
    "    prompt = f\"\"\"{prompt_start} {all_text} {format_prompt}\"\"\"\n",
    "    \n",
    "    # Iterate over the num_tries times\n",
    "    all_trial_responses = {}\n",
    "    for trial_index in range(num_tries):\n",
    "        #print(f\"trial: {trial_index}\")\n",
    "        trial_name = f\"Trial_{trial_index+1}\"\n",
    "        try:\n",
    "            #response if parsed in query_open_ai\n",
    "            response = query_open_ai(prompt, temperature = temperature, max_tokens = max_tokens)\n",
    "            \n",
    "            #print(response)\n",
    "            response_parsed = extract_response(response, json_obj=True)\n",
    "            #print(response_parsed)\n",
    "        except APIConnectionError as e:\n",
    "            error_msg = f\"APIConnectionError: {e}\"\n",
    "            logToWfl(error_msg)\n",
    "            print(error_msg)\n",
    "            response_parsed = pd.DataFrame([{\"OpenAI Server Error\": error_msg}])\n",
    "        except Exception as e:\n",
    "            error_msg = f\"An error occurred: {e}\"\n",
    "            logToWfl(error_msg)\n",
    "            print(error_msg)\n",
    "            response_parsed = pd.DataFrame([{\"Server Error\": error_msg}])\n",
    "        all_trial_responses[trial_name] = response_parsed\n",
    "        \n",
    "        prog = ((cur_file_cnt - 1)/all_file_cnt) + (1/all_file_cnt) * ((trial_index+1)/num_tries)\n",
    "        logProgressToWfl( \"{:.0%}\".format(prog))\n",
    "        print(f\"Overall progress: {prog:.0%}\")\n",
    "    return all_trial_responses\n",
    "\n",
    "# #test\n",
    "# #878010494_captions.vtt or 878010491_captions.vtt or 875691055_captions.vtt\n",
    "# openai_api_key = \"your key\"\n",
    "# openai.api_key = openai_api_key\n",
    "# log_file_name = \"situation_finder_evalution_wf.log\"\n",
    "# #prompt_filename = \"math_error_filter_prompt.txt\"\n",
    "# #prompt_filename = \"Plus_math_error_evaluation_prompt_gpt_4o.txt\"\n",
    "# prompt_filename = \"math_error_by_line_prompt_gpt35.txt\"\n",
    "# #response = evaluation_file(\"drive-download-20250325T133806Z-001/878010491_captions.vtt\", prompt_filename, 1, 1, num_tries=3) \n",
    "# #response = evaluation_file(\"convertedDelimited.csv\", prompt_filename, 1, 1, col = \"Text\", num_tries=3) \n",
    "# response = evaluation_file(\"018b3e14-8717-7772-f9c9-f259993de6b3.txt\", prompt_filename, 1, 1, num_tries=3)\n",
    "# print(\"Trial_1\")\n",
    "# print(response[\"Trial_1\"])\n",
    "# print(\"Trial_2\")\n",
    "# print(response[\"Trial_2\"])\n",
    "# print(\"Trial_3\")\n",
    "# print(response[\"Trial_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20d44b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 878010491_captions_converted.csv\n",
      "Overall progress: 33%\n",
      "Overall progress: 67%\n",
      "Overall progress: 100%\n"
     ]
    }
   ],
   "source": [
    "#test situation filter\n",
    "command_line=False\n",
    "if command_line:\n",
    "    parser = argparse.ArgumentParser(description=\"Tutor Evaluation\")\n",
    "    parser.add_argument('-programDir', type=str, help='the component program directory')\n",
    "    parser.add_argument('-workingDir', type=str, help='the component instance working directory')\n",
    "    parser.add_argument(\"-transcript_file_type\", help=\"transcript file type\", type=str, required=True, choices=['Zip of VTT Files', 'Zip of CSV Files', 'Zip of TXT Files', 'VTT', 'CSV', 'TXT'])\n",
    "    parser.add_argument(\"-openai_api_key\", help=\"OpenAI API Key\", type=str, required=True)\n",
    "    parser.add_argument(\"-max_token\", help=\"maximum token returned from gpt\", type=int, default=200)\n",
    "    parser.add_argument(\"-number_of_trials\", help=\"number of trials to query gpt\", type=int, default=3)\n",
    "    parser.add_argument(\"-temperature\", help=\"temperature for gpt engine\", type=float, default=1.0)\n",
    "    parser.add_argument(\"-utterances_col\", help=\"the transcript uterence column when the input file is CSV\", type=str)       \n",
    "    #only for WF:\n",
    "    parser.add_argument(\"-fileIndex\", nargs=2, action='append')\n",
    "    parser.add_argument(\"-node\", action='append')\n",
    "    #only for pure command line runnging\n",
    "    parser.add_argument(\"-transcript_file\")\n",
    "    parser.add_argument(\"-prompt_file\")\n",
    "    #args = parser.parse_args()\n",
    "    args, option_file_index_args = parser.parse_known_args()\n",
    "    working_dir = args.workingDir\n",
    "    program_dir = args.programDir\n",
    "    if working_dir is None:\n",
    "        working_dir = \".//\"\n",
    "    if program_dir is None:\n",
    "        program_dir = \".//\"\n",
    "    transcript_file_type = args.transcript_file_type\n",
    "    openai_api_key = args.openai_api_key\n",
    "    max_token = args.max_token\n",
    "    num_trails = args.number_of_trials\n",
    "    temperature = args.temperature\n",
    "    utterances_col = args.utterances_col\n",
    "    transcript_file = args.transcript_file\n",
    "    prompt_file = args.prompt_file\n",
    "    \n",
    "    #process files for WF:\n",
    "    if args.node is not None:\n",
    "        for x in range(len(args.node)):\n",
    "            if (args.node[x][0] == \"0\" and args.fileIndex[x][0] == \"0\"):\n",
    "                transcript_file = args.fileIndex[x][1]\n",
    "            if (args.node[x][0] == \"1\" and args.fileIndex[x][0] == \"0\"):\n",
    "                prompt_file = args.fileIndex[x][1]\n",
    "     \n",
    "#for test                  \n",
    "else:\n",
    "    working_dir = \".//\"\n",
    "    program_dir = \".//\"\n",
    "    transcript_file_type = \"CSV\" #Zip of VTT Files, Zip of CSV Files, Zip of TXT Files, VTT, CSV, TXT\n",
    "    openai_api_key = \"your key\"\n",
    "    #test_vtt.zip, test_text_transcripts.zip, ../NTO/test_csv.zip,drive-download-20250325T133806Z-001/878010491_captions.vtt, 878010491_captions_converted.csv, A2 Transcript of user 216886 tutor session on 2023-09-25 LS id 4760786.vtt\n",
    "    transcript_file = \"878010491_captions_converted.csv\" \n",
    "    #prompt_file = \"math_error_filter_prompt.txt\" math_error_evaluation_prompt.txt math_error_by_line_prompt_gpt35.txt\n",
    "    prompt_file = \"math_error_evaluation_prompt.txt\" \n",
    "    max_token = 200\n",
    "    num_trails = 3\n",
    "    temperature = 1\n",
    "    utterances_col = \"Text\"\n",
    "    \n",
    "#ensure required arguments are present:\n",
    "if transcript_file is None:\n",
    "    print(\"The required argument, transcript_file, is missing\")\n",
    "    sys.exit(1)\n",
    "if prompt_file is None:\n",
    "    print(\"The required argument, prompt_file, is missing\")\n",
    "    sys.exit(1)\n",
    "if transcript_file_type is None:\n",
    "    print(\"The required argument, transcript_file_type, is missing\")\n",
    "    sys.exit(1)\n",
    "if (transcript_file_type == \"CSV\" or transcript_file_type == \"Zip of CSV Files\") and utterances_col is None:\n",
    "    print(\"The argument, utterances_col, is required for CSV transcript file and is missing\")\n",
    "    sys.exit(1)    \n",
    "\n",
    "\n",
    "#test\n",
    "# print(transcript_file_type)\n",
    "# print(openai_api_key)\n",
    "# print(num_trails)\n",
    "# print(temperature)\n",
    "# print(utterances_col)\n",
    "# print(transcript_file)\n",
    "# print(prompt_file)\n",
    "\n",
    "all_results = {}\n",
    "log_file_name = os.path.join(working_dir, \"tutor_transcript_evaluation.wfl\")\n",
    "#version 3.5\n",
    "openai.api_key = openai_api_key\n",
    "#version 4\n",
    "#client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "if transcript_file_type == 'Zip of VTT Files' or transcript_file_type == 'Zip of TXT Files':\n",
    "    unzipped_file_folder = os.path.join(working_dir, \"unzipped_files_temp\")\n",
    "    all_files = get_files_in_zip(transcript_file, unzipped_file_folder)\n",
    "    cnt = 1\n",
    "    for a_transcript_file in all_files:\n",
    "        #delete the working dir:\n",
    "        cleaned_transcript_file = a_transcript_file.replace(unzipped_file_folder, \"\", 1)\n",
    "        cleaned_transcript_file = clean_filename(cleaned_transcript_file)\n",
    "        logToWfl(f\"Processing file: {cleaned_transcript_file}\")\n",
    "        print(f\"Processing file: {cleaned_transcript_file}\")\n",
    "        try: \n",
    "            response = evaluation_file(a_transcript_file, prompt_file, cnt, len(all_files), num_tries=num_trails,\n",
    "                                                  temperature=temperature, max_tokens=max_token) \n",
    "            #a_transcript_file = a_transcript_file.replace(unzipped_file_folder, \"\", 1)\n",
    "            all_results[cleaned_transcript_file] = response\n",
    "        except FileTypeError as e:\n",
    "            logToWfl(f\"File error occurred for file {a_transcript_file}: {e}\")\n",
    "            print(f\"File error occurred for file {a_transcript_file}: {e}\")\n",
    "            all_results[cleaned_transcript_file] = pd.DataFrame([{\"Other Error\": f\"File error occurred for file {a_transcript_file}: {e}\"}])\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            logToWfl(f\"An error occurred for file {transcript_file}: {e}\")\n",
    "            print(f\"An error occurred for file {transcript_file}: {e}\")\n",
    "            all_results[cleaned_transcript_file] = pd.DataFrame([{\"Other Error\": f\"An error occurred for file {a_transcript_file}: {e}\"}])\n",
    "            continue\n",
    "        cnt = cnt + 1\n",
    "                \n",
    "    #delete the temp folder\n",
    "    if os.path.exists(unzipped_file_folder) and os.path.isdir(unzipped_file_folder):\n",
    "        shutil.rmtree(unzipped_file_folder)\n",
    "        \n",
    "elif transcript_file_type == 'Zip of CSV Files':\n",
    "    unzipped_file_folder = os.path.join(working_dir, \"unzipped_files_temp\")\n",
    "    all_files = get_files_in_zip(transcript_file, unzipped_file_folder)\n",
    "    cnt = 1\n",
    "    for a_transcript_file in all_files:\n",
    "        #delete the working dir:\n",
    "        cleaned_transcript_file = a_transcript_file.replace(unzipped_file_folder, \"\", 1)\n",
    "        cleaned_transcript_file = clean_filename(cleaned_transcript_file)\n",
    "        logToWfl(f\"Processing file: {cleaned_transcript_file}\")\n",
    "        print(f\"Processing file: {cleaned_transcript_file}\")\n",
    "        try: \n",
    "            response = evaluation_file(a_transcript_file, prompt_file, cnt, len(all_files), num_tries=num_trails, col=utterances_col,\n",
    "                                                  temperature=temperature, max_tokens=max_token)\n",
    "            #a_transcript_file = a_transcript_file.replace(unzipped_file_folder, \"\", 1)\n",
    "            all_results[cleaned_transcript_file] = response\n",
    "        except FileTypeError as e:\n",
    "            logToWfl(f\"File error occurred for file {a_transcript_file}: {e}\")\n",
    "            print(f\"File error occurred for file {a_transcript_file}: {e}\")\n",
    "            all_results[cleaned_transcript_file] = pd.DataFrame([{\"Other Error\": f\"File error occurred for file {a_transcript_file}: {e}\"}])\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            logToWfl(f\"An error occurred for file {a_transcript_file}: {e}\")\n",
    "            print(f\"An error occurred for file {a_transcript_file}: {e}\")\n",
    "            all_results[cleaned_transcript_file] = pd.DataFrame([{\"Other Error\": f\"An error occurred for file {a_transcript_file}: {e}\"}])\n",
    "            continue\n",
    "        cnt = cnt + 1\n",
    "                \n",
    "    #delete the temp folder\n",
    "    if os.path.exists(unzipped_file_folder) and os.path.isdir(unzipped_file_folder):\n",
    "        shutil.rmtree(unzipped_file_folder)\n",
    "            \n",
    "elif transcript_file_type == 'VTT' or transcript_file_type == 'TXT':\n",
    "    cleaned_transcript_file = transcript_file.replace(working_dir, \"\", 1)\n",
    "    cleaned_transcript_file = clean_filename(cleaned_transcript_file)\n",
    "    cleaned_transcript_file = os.path.basename(cleaned_transcript_file)\n",
    "    logToWfl(f\"Processing file: {cleaned_transcript_file}\")\n",
    "    print(f\"Processing file: {cleaned_transcript_file}\")\n",
    "    try:\n",
    "        response = evaluation_file(transcript_file, prompt_file, 1, 1, num_tries=num_trails,\n",
    "                                              temperature=temperature, max_tokens=max_token)\n",
    "        all_results[cleaned_transcript_file] = response\n",
    "    except FileTypeError as e:\n",
    "        logToWfl(f\"File error occurred for file {transcript_file}: {e}\")\n",
    "        print(f\"File error occurred for file {transcript_file}: {e}\")\n",
    "        all_results[cleaned_transcript_file] = pd.DataFrame([{\"Other Error\": f\"File error occurred for file {transcript_file}: {e}\"}])\n",
    "    except Exception as e:\n",
    "        logToWfl(f\"An error occurred for file {transcript_file}: {e}\")\n",
    "        print(f\"An error occurred for file {transcript_file}: {e}\")\n",
    "        all_results[cleaned_transcript_file] = pd.DataFrame([{\"Other Error\": f\"An error occurred for file {transcript_file}: {e}\"}])\n",
    "        \n",
    "elif transcript_file_type == 'CSV':\n",
    "    cleaned_transcript_file = transcript_file.replace(working_dir, \"\", 1)\n",
    "    cleaned_transcript_file = clean_filename(cleaned_transcript_file)\n",
    "    cleaned_transcript_file = os.path.basename(cleaned_transcript_file)\n",
    "    logToWfl(f\"Processing file: {cleaned_transcript_file}\")\n",
    "    print(f\"Processing file: {cleaned_transcript_file}\")\n",
    "    try:\n",
    "        response = evaluation_file(transcript_file, prompt_file, 1, 1, num_tries=num_trails, col=utterances_col,\n",
    "                                              temperature=temperature, max_tokens=max_token) #\n",
    "        all_results[cleaned_transcript_file] = response\n",
    "    except FileTypeError as e:\n",
    "        logToWfl(f\"File error occurred for file {transcript_file}: {e}\")\n",
    "        print(f\"File error occurred for file {transcript_file}: {e}\")\n",
    "        all_results[cleaned_transcript_file] = pd.DataFrame([{\"Other Error\": f\"File error occurred for file {transcript_file}: {e}\"}])\n",
    "    except Exception as e:\n",
    "        logToWfl(f\"An error occurred for file {transcript_file}: {e}\")\n",
    "        print(f\"An error occurred for file {transcript_file}: {e}\")\n",
    "        all_results[cleaned_transcript_file] = pd.DataFrame([{\"Other Error\": f\"An error occurred for file {transcript_file}: {e}\"}])\n",
    "        \n",
    "# print(\"all results\")\n",
    "# print(all_results)\n",
    "\n",
    "#output result\n",
    "#make df with \n",
    "df = None\n",
    "columns = ['Transcript File Name']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "#is a dict with file name as key, a dict as value which has trial name is key and value is a dataframe\n",
    "for transcript_file, transcript_value in all_results.items():\n",
    "    for trial_name, data_df in transcript_value.items():\n",
    "        if data_df is None or data_df.empty:\n",
    "            new_row = {}\n",
    "            new_row['Transcript Name'] = transcript_file\n",
    "            new_row['Trial'] = trial_name\n",
    "            new_row['Response'] = \"Blank response from server\"\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        elif not isinstance(data_df, pd.DataFrame):\n",
    "            new_row = {}\n",
    "            new_row['Transcript Name'] = transcript_file\n",
    "            new_row['Trial'] = trial_name\n",
    "            new_row['Response'] = data_df\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        else:\n",
    "            data_columns = data_df.columns\n",
    "            for data_index, data_row in data_df.iterrows():\n",
    "                new_row = {}\n",
    "                new_row['Transcript Name'] = transcript_file\n",
    "                new_row['Trial'] = trial_name\n",
    "                for data_col in data_columns:\n",
    "                    new_row[data_col] = data_row[data_col]\n",
    "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "df.to_csv(os.path.join(working_dir,'tutor_evaluation_result.csv'), index=False) \n",
    "                \n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12cdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "36_env",
   "language": "python",
   "name": "36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
