{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afd2a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from jproperties import Properties\n",
    "import datetime as dt\n",
    "from settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ddec62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set constant from settings\n",
    "#set parameters\n",
    "MAX_TOKENS = settings.MAX_TOKENS\n",
    "TEMPERATURE = settings.TEMPERATURE\n",
    "RUN_UP_TO = settings.RUN_UP_TO  \n",
    "MODEL = settings.MODEL\n",
    "\n",
    "lesson_prompt_dic = {\"Helping Students Manage Inequity\" : \"Helping Students Manage Inequity.csv\",\n",
    "                    \"Determining What students Know\" : \"Determining What students Know.csv\",\n",
    "                    \"Giving Effective Praise\" : \"Giving Effective Praise.csv\",\n",
    "                    \"Reacting to Errors\" : \"Reacting to Errors.csv\"}\n",
    "\n",
    "#fresh new log file\n",
    "log_file_name = \"AI_lesson_scoring.wfl\"\n",
    "logFile = open(log_file_name, \"w\")\n",
    "logFile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "723c80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_response(response_obj, json=False):\n",
    "    role = response_obj.choices[0].message.role\n",
    "    content = response_obj.choices[0].message.content\n",
    "    if json:\n",
    "        return {\"role\": role, \"content\": content}\n",
    "    else:\n",
    "        return (role, content)\n",
    "    \n",
    "def logProgressToWfl(progressMsg):\n",
    "    logFile = open(log_file_name, \"a\")\n",
    "    now = dt.datetime.now()\n",
    "    progressPrepend = \"%Progress::\"\n",
    "    logFile.write(progressPrepend + \"@\" + str(now) + \"@\" + progressMsg + \"\\n\");\n",
    "    logFile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f448e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_inputs(client, inputs, prompt_start, prompt_format):\n",
    "    new_df = pd.DataFrame(columns = ['score','rationale'])\n",
    "    #not over RUN_UP_TO, If an upper bound is set, get response less than this number\n",
    "    if RUN_UP_TO >=  0:  \n",
    "        inputs_upto = inputs[:RUN_UP_TO]\n",
    "    else:\n",
    "        inputs_upto = inputs  # Take the whole set of responses\n",
    "    loop_cnt = 1\n",
    "    for inpt in inputs_upto:\n",
    "        progress = loop_cnt/len(inputs_upto)\n",
    "        progress = f\"{progress * 100:.{0}f}%\"\n",
    "        logProgressToWfl(progress)\n",
    "        new_row = {} \n",
    "        overall_history = [{\"role\": \"system\", \"content\": prompt_start}, \n",
    "                           {\"role\": \"user\", \"content\": inpt}, \n",
    "                           {\"role\": \"system\", \"content\": prompt_format}]\n",
    "        openai_out = client.chat.completions.create(model=MODEL, messages=overall_history, max_tokens=MAX_TOKENS, temperature = TEMPERATURE)\n",
    "        role, content = extract_response(openai_out)\n",
    "        #print(role)\n",
    "        #print(content)\n",
    "        # We now need to parse the JSON into rational and score\n",
    "        try:\n",
    "            content_json = json.loads(content)  # Run response through JSON\n",
    "            score = str(content_json[\"Score\"])  # Cast to string to avoid type inequality\n",
    "            rationale = str(content_json[\"Rationale\"])  # Fetch the rationale\n",
    "            new_row['score'] = score\n",
    "            new_row['rationale'] = rationale\n",
    "        except:\n",
    "            new_row['score'] =  \"---\"\n",
    "            new_row['rationale'] = \"---\" \n",
    "        new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True) # Failsafe\n",
    "        loop_cnt = loop_cnt + 1\n",
    "    \n",
    "    #if data is more than RUN_UP_TO\n",
    "    if len(inputs) > len(new_df):\n",
    "        for i in range(len(inputs)-len(new_df)):\n",
    "            new_row = {'score':\"---\", 'rationale':\"---\"}\n",
    "            new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True) \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84975468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                      \r"
     ]
    }
   ],
   "source": [
    "#test command\n",
    "#test: predict, no key\n",
    "#C:\\Users\\hchen\\Anaconda3\\python.exe ai_lesson_scoring.py -programDir . -workingDir . -userId hcheng -have_api_key No -lesson \"Helping Students Manage Inequity\" -predict_explain Predict -scoringCol_nodeIndex 0 -scoringCol_fileIndex 0 -scoringCol Input -use_config Yes -node 0 -fileIndex 0 HSME_predict.csv\n",
    "#test: predict, config file\n",
    "#C:\\Users\\hchen\\Anaconda3\\python.exe ai_lesson_scoring.py -programDir . -workingDir . -userId hcheng -have_api_key Yes -lesson \"Helping Students Manage Inequity\" -predict_explain Explain -scoringCol_nodeIndex 0 -scoringCol_fileIndex 0 -scoringCol Input -use_config Yes -node 0 -fileIndex 0 HSME_predict.csv -node 1 -fileIndex 0 config_file.txt\n",
    "#test: explain with key\n",
    "#C:\\Users\\hchen\\Anaconda3\\python.exe ai_lesson_scoring.py -programDir . -workingDir . -userId hcheng -have_api_key Yes -lesson \"Helping Students Manage Inequity\" -openai_api_key somekey -predict_explain Explain -scoringCol_nodeIndex 0 -scoringCol_fileIndex 0 -scoringCol Input -use_config No -node 0 -fileIndex 0 HSME_predict.csv -node 1 -fileIndex 0 config_file.txt\n",
    "command_line = False\n",
    "if command_line:\n",
    "    parser = argparse.ArgumentParser(description=\"AI Lessons Scoring\")\n",
    "    parser.add_argument('-programDir', type=str, help='the component program directory')\n",
    "    parser.add_argument('-workingDir', type=str, help='the component instance working directory')\n",
    "    parser.add_argument(\"-fileIndex\", nargs=2, action='append')\n",
    "    parser.add_argument(\"-node\", action='append')\n",
    "    parser.add_argument(\"-lesson\", help=\"4 lessons to pick\", type=str, required=True)\n",
    "    parser.add_argument(\"-predict_explain\", help=\"predict or explain\", type=str, required=True, choices=['Predict', 'Explain'])\n",
    "    parser.add_argument(\"-scoringCol\", type=str, help='column to score')\n",
    "    parser.add_argument(\"-have_api_key\", help=\"Boolean to decide which key to use.\", type=str, choices=['Yes', 'No'], default=\"Yes\")\n",
    "    parser.add_argument(\"-use_config\", help=\"Boolean to decide if key is from config file.\", type=str, choices=['Yes', 'No'], default=\"Yes\")\n",
    "    parser.add_argument(\"-openai_api_key\", help=\"API key for the account that we want to use azure\", type=str)\n",
    "    \n",
    "    args, option_file_index_args = parser.parse_known_args()\n",
    "    \n",
    "    working_dir = args.workingDir\n",
    "    program_dir = args.programDir\n",
    "    data_file = None\n",
    "    config_file = None\n",
    "    \n",
    "    for x in range(len(args.node)):\n",
    "        if (args.node[x][0] == \"0\" and args.fileIndex[x][0] == \"0\"):\n",
    "            data_file = args.fileIndex[x][1]\n",
    "        if (args.node[x][0] == \"1\" and args.fileIndex[x][0] == \"0\"):\n",
    "            config_file = args.fileIndex[x][1]\n",
    "            \n",
    "    column_to_score = args.scoringCol\n",
    "    lesson = args.lesson\n",
    "    predict_explain = (args.predict_explain).lower()\n",
    "    \n",
    "    api_key = \"\"\n",
    "    have_api_key = (args.have_api_key).lower()\n",
    "    if args.have_api_key == \"No\":\n",
    "        api_key = settings.OPENAI_API_KEY\n",
    "    else:\n",
    "        if args.use_config == \"Yes\":\n",
    "            if config_file is not None:\n",
    "                configs = Properties()\n",
    "                with open(config_file, 'rb') as cfile:\n",
    "                    configs.load(cfile)\n",
    "                    if configs.get(\"OPENAI_API_KEY\") is not None:\n",
    "                        api_key = configs.get(\"OPENAI_API_KEY\").data\n",
    "        else:\n",
    "            api_key = args.openai_api_key\n",
    "                    \n",
    "else:\n",
    "    working_dir = \".\"\n",
    "    program_dir = \".\"\n",
    "    data_file = \"HSME_predict.csv\"\n",
    "    config_file = \"config_file.txt\"\n",
    "    column_to_score = \"Input\"\n",
    "    lesson = \"Helping Students Manage Inequity\"\n",
    "    #lesson = \"Giving Effective Praise\"\n",
    "    predict_explain = \"predict\"\n",
    "    api_key = settings.OPENAI_API_KEY\n",
    "    \n",
    "# print(data_file)\n",
    "# print(config_file)\n",
    "# print(column_to_score)\n",
    "# print(lesson)\n",
    "# print(predict_explain)\n",
    "# print(api_key)\n",
    "\n",
    "\n",
    "#data file\n",
    "df = pd.read_csv(data_file, encoding=\"ISO-8859-1\")\n",
    "inputs_to_score = df[column_to_score].tolist()\n",
    "\n",
    "#prompt file\n",
    "prompt_file_name = lesson_prompt_dic[lesson]\n",
    "prompt_file = None\n",
    "if prompt_file_name is not None and prompt_file_name != \"\":\n",
    "    prompt_file = os.path.join(program_dir, \"program\")\n",
    "    prompt_file = os.path.join(prompt_file, prompt_file_name)\n",
    "else:\n",
    "    sys.exit(f'Lesson: {lesson} is not supported')\n",
    "df_prompt = None\n",
    "#check if prompt_file exist\n",
    "if os.path.exists(prompt_file):\n",
    "    df_prompt = pd.read_csv(prompt_file, encoding=\"ISO-8859-1\")\n",
    "else:\n",
    "    sys.exit(f'Prompt file not found for lesson: {lesson}')\n",
    "    \n",
    "scoring_prompt_start = df_prompt.loc[df_prompt['type'] == predict_explain, 'scoring_prompt_start'].values[0]\n",
    "scoring_format_prompt = df_prompt.loc[df_prompt['type'] == predict_explain, 'scoring_format_prompt'].values[0]\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "scored_df = score_inputs(client, inputs_to_score, scoring_prompt_start, scoring_format_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52c6341e",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '.\\\\HSME_predict_scored.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m new_file_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(data_file))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_scored\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(data_file))[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m new_file_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(working_dir, new_file_name)\n\u001b[1;32m---> 14\u001b[0m df_with_score\u001b[38;5;241m.\u001b[39mto_csv(new_file_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '.\\\\HSME_predict_scored.csv'"
     ]
    }
   ],
   "source": [
    "#concatenate with original df\n",
    "df_with_score = pd.concat([df, scored_df], axis=1)\n",
    "#reorder column and put new columns next to column_to_score\n",
    "df_with_score_cols = df_with_score.columns.tolist()\n",
    "column_to_score_ind = df_with_score_cols.index(column_to_score)\n",
    "new_cols =  df_with_score_cols[:column_to_score_ind+1] + df_with_score_cols[len(df_with_score_cols)-2:] + df_with_score_cols[column_to_score_ind+1:len(df_with_score_cols)-2]\n",
    "df_with_score = df_with_score[new_cols] \n",
    "#rename\n",
    "df_with_score.rename(columns={'score': 'openAI_score', 'rationale': 'openAI_rationale'}, inplace=True)\n",
    "\n",
    "#new file name\n",
    "new_file_name = os.path.splitext(os.path.basename(data_file))[0] + \"_scored\" + os.path.splitext(os.path.basename(data_file))[1]\n",
    "new_file_name = os.path.join(working_dir, new_file_name)\n",
    "df_with_score.to_csv(new_file_name, index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f1703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
