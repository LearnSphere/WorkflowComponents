{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_line = False #false for jupyter notebook\n",
    "problem_file = \"\"\n",
    "# transaction_file = \"\"\n",
    "workingDir = \"\"\n",
    "if command_line:\n",
    "    #command line\n",
    "    parser = argparse.ArgumentParser(description='Process datashop file.')\n",
    "    parser.add_argument('-programDir', type=str, help='the component program directory')\n",
    "    parser.add_argument('-workingDir', type=str, help='the component instance working directory')\n",
    "    parser.add_argument(\"-node\", nargs=1, action='append')\n",
    "    parser.add_argument(\"-fileIndex\", nargs=1, action='append')\n",
    "    args, option_file_index_args = parser.parse_known_args()\n",
    "    print(args.fileIndex)\n",
    "    transaction_file = args.fileIndex[0][1]\n",
    "    problem_file = args.fileIndex[0][1]\n",
    "    workingDir = args.workingDir\n",
    "#     print(transaction_file)\n",
    "    print(problem_file)\n",
    "else:\n",
    "    #problems file\n",
    "    problem_file = \"problem.txt\"\n",
    "\n",
    "#     #transactions file\n",
    "    transaction_file = \"trans.txt\"\n",
    "    workingDir = \".\"\n",
    "\n",
    "\n",
    "#make sure the output folder exist\n",
    "outputPath = workingDir + \"/final\"\n",
    "if not os.path.exists(outputPath):\n",
    "    os.makedirs(outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Learn By Doing (LBD) and Did I Get This (DIGT) Activities per Module\n",
    "#### Last Updated 05-25-2022 3:44 pm EST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The below call can be used to load multiple files, but it's fine to load a single problem file like this\n",
    "# file_name = glob.glob(\"problem.txt\")\n",
    "\n",
    "#Create a dictionary to represent each module in the course\n",
    "modules = {}\n",
    "\n",
    "#Create a dataframe of the problem file we read in\n",
    "df = pd.read_csv(problem_file,delimiter=\"\\t\", index_col='Row')\n",
    "\n",
    "#get transaction file\n",
    "tx = pd.read_csv(transaction_file,delimiter=\"\\t\", index_col='Row')\n",
    "\n",
    "#get the first occurence of each problem name ---correspond to oli:purpose\n",
    "\n",
    "#Grab every unique module in the course and initialize a dictionary based on them.\n",
    "#The key is the module name\n",
    "#The value is a list, where the first index into the list will be a dictionary of \"Did I Get This\" acitivites\n",
    "#The second index into the list is a dictionary of \"Learn by Doing\" activities\n",
    "mods = df['Problem Hierarchy'].unique()\n",
    "\n",
    "for mod in mods:\n",
    "    modules[mod] = [{},{},{}]\n",
    "\n",
    "#We iterate over each row in the dataframe (akin to going down each row in a CSV file)\n",
    "for i, j in df.iterrows():\n",
    "    #problem name in each row\n",
    "    problem_name = j['Problem Name']\n",
    "    \n",
    "    #first occurence of the problem name in transaction file\n",
    "    prob_index = (tx['Problem Name'] == str(problem_name)).idxmax()\n",
    "    \n",
    "    #get type\n",
    "    prob_type = tx.iloc[i]['CF (oli:purpose)']\n",
    "    #print(problem_name)\n",
    "\n",
    "    #module name in each row\n",
    "    module_name = j['Problem Hierarchy']\n",
    "\n",
    "    #Grab the Did I Get This and Learn By Doing dictionaries\n",
    "    digt = modules[module_name][0]\n",
    "    lbd = modules[module_name][1]\n",
    "    none = modules[module_name][2]\n",
    "\n",
    "    #If the problem name does not mention 'quiz', meaning it's a formative (DIGT or LBD) activity\n",
    "#     if 'quiz' not in str(prob_type):\n",
    "        \n",
    "    if 'didigetthis' in str(prob_type):\n",
    "        #If we have not come across this DIGT problem in the module before, we add it to the dictionary\n",
    "        if problem_name not in digt.keys():\n",
    "            digt[problem_name] = 1\n",
    "            modules[module_name][0] = digt\n",
    "\n",
    "    elif 'learnbydoing' in str(prob_type):\n",
    "        #If we have not come across this LBD problem in the module before, we add it to the dictionary\n",
    "        if problem_name not in lbd.keys():\n",
    "            lbd[problem_name] = 1\n",
    "            modules[module_name][1] = lbd\n",
    "    else:\n",
    "        if problem_name not in none.keys():\n",
    "            none[problem_name] = 1\n",
    "            modules[module_name][2] = none\n",
    "            \n",
    "\n",
    "#This code just loops over our modules dictionary, creates a list of the module name, # of DIGT, # of LBDs and then\n",
    "#converts it to a dataframe so we can save it as a .csv file\n",
    "results = []\n",
    "for key, value in modules.items():\n",
    "    current_mod = key\n",
    "    digts = len(modules[current_mod][0])\n",
    "    lbds = len(modules[current_mod][1])\n",
    "    none = len(modules[current_mod][2])\n",
    "    results.append([current_mod.split('module ')[1], digts, lbds, none])\n",
    "\n",
    "df = pd.DataFrame(results, columns =['Module', 'Did I Get This', 'Learn By Doing', 'Uncategorized'])\n",
    "df.to_csv(outputPath + \"/activities_per_module.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Quiz Data per Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below call can be used to load multiple files, but it's fine to load a single problem file like this\n",
    "# file_name = glob.glob(\"problem.txt\")\n",
    "\n",
    "#Create a dataframe of the problem file we read in\n",
    "df = pd.read_csv(problem_file,delimiter=\"\\t\", index_col='Row')\n",
    "\n",
    "modules = df['Problem Hierarchy'].unique()\n",
    "\n",
    "length = len(modules)\n",
    "\n",
    "\n",
    "#Quiz Scores Spreadsheet\n",
    "# list_of_files = glob.glob(\"problem.txt\")\n",
    "# modules = ['sequence General Chemistry I, unit Foundations of Chemistry, module Atomic Theory',\n",
    "#           'sequence General Chemistry I, unit Chemical Reactions, module Chemical Reactions and Equations',\n",
    "#           'sequence General Chemistry I, unit Measurement, module Measurements',\n",
    "#           'sequence General Chemistry I, unit Composition of Substances and Solutions, module Aqueous Solutions',\n",
    "#           'sequence General Chemistry I, unit Reactions and Stoichiometry, module Reaction Stoichiometry']\n",
    "\n",
    "quiz_data = {}\n",
    "\n",
    "#These are gathered from the code block above\n",
    "for module in modules:\n",
    "\n",
    "\n",
    "        #Our dataframe only consists of Atomic Theory problems now\n",
    "        at_df = df.loc[module == df['Problem Hierarchy']]\n",
    "\n",
    "        #Get all student_ids in a list that did atomic theory work\n",
    "        unique_student_ids = df['Anon Student Id'].unique()\n",
    "\n",
    "        for student_id in unique_student_ids:\n",
    "            permod = {}\n",
    "            s_df = at_df.loc[(df['Anon Student Id'] == student_id)]\n",
    "            if not s_df.empty:\n",
    "                atq_df = s_df.loc[at_df['Problem Name'].str.contains('quiz')]\n",
    "                if not atq_df.empty:\n",
    "                    attempts = corrects = atq_df['Problem View'].tail(1).values[0]\n",
    "                    final_score = atq_df['Corrects'].tail(1).values[0]\n",
    "                    quiz_score = atq_df['Avg Corrects'].tail(1).values[0]\n",
    "                    first_attempt_correct = atq_df['Corrects'].head(1).values[0]\n",
    "                    quiz_steps = atq_df['Steps'].tail(1).values[0]\n",
    "                    if student_id in quiz_data.keys():\n",
    "                        quiz_data[student_id][module] = [attempts, final_score, quiz_score, first_attempt_correct, quiz_steps]\n",
    "                    else:\n",
    "                        permod[module] = [attempts, final_score, quiz_score, first_attempt_correct, quiz_steps]\n",
    "                        quiz_data[student_id] = permod\n",
    "                else:\n",
    "                    if student_id in quiz_data.keys():\n",
    "                        quiz_data[student_id][module] = [0, 0, 0, 0, 0]\n",
    "                    else:\n",
    "                        permod[module] = [0, 0, 0, 0, 0]\n",
    "                        quiz_data[student_id] = permod\n",
    "            else:\n",
    "                if student_id in quiz_data.keys():\n",
    "                        quiz_data[student_id][module] = [0, 0, 0, 0, 0]\n",
    "                else:\n",
    "                    permod[module] = [0, 0, 0, 0, 0]\n",
    "                    quiz_data[student_id] = permod\n",
    "    #columns: student ID, prob hierarchy, attempts, final_score, quiz_score, first_attempt_correct, quiz_steps\n",
    "    #rows\n",
    "\n",
    "dfquiz = {}\n",
    "for stdnt, moddata in quiz_data.items():\n",
    "    c = moddata.copy()\n",
    "    for mod, data in c.items():\n",
    "        if stdnt in dfquiz.keys():\n",
    "            dfquiz[stdnt].extend(data)\n",
    "        else:\n",
    "            dfquiz[stdnt] = data\n",
    "# print(dfquiz)\n",
    "\n",
    "#make the final dataframe\n",
    "df_quiz2 = pd.DataFrame(columns=['stuID', 'prob-hierarchy', 'attempts', 'final-score', 'quiz-score', 'first-attempt-correct', 'quiz-steps'])\n",
    "\n",
    "for k,v in dfquiz.items():\n",
    "    ph = 1\n",
    "    for x in range(length):\n",
    "\n",
    "        L = []\n",
    "        L.append(k)\n",
    "        L.append(ph)\n",
    "#         print(len(v[(x*5):(x*5)+5]))\n",
    "        L=L+v[(x*5):(x*5)+5]\n",
    "        df_quiz2.loc[len(df_quiz2)] = L\n",
    "        ph=ph+1\n",
    "\n",
    "#df_quiz = pd.DataFrame.from_dict(dfquiz, orient=\"index\")\n",
    "\n",
    "# df_quiz.columns = ['stuID', 'hierarchy', 'attempts', 'final', 'quiz', 'first', 'steps']\n",
    "\n",
    "# df_quiz.columns = ['attempts-at', 'final-at', 'grade-at', 'first-at', 'steps-at',\n",
    "#                   'attempts-cre', 'final-cre', 'grade-cre', 'first-cre', 'steps-cre',\n",
    "#                   'attempts-m', 'final-m', 'grade-m', 'first-m', 'steps-m',\n",
    "#                   'attempts-as', 'final-as', 'grade-as', 'first-as', 'steps-as',\n",
    "#                   'attempts-rs', 'final-rs', 'grade-rs', 'first-rs', 'steps-rs']\n",
    "df_quiz2.to_csv(outputPath + \"/s_student_quiz.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Performance on the Formative Assessments per Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formative Assessments for Chemistry\n",
    "#The below call can be used to load multiple files, but it's fine to load a single problem file like this\n",
    "# list_of_files = glob.glob(transaction_file)\n",
    "# file_name = glob.glob(problem_file)\n",
    "\n",
    "#Create a dataframe of the problem file we read in\n",
    "df = pd.read_csv(problem_file,delimiter=\"\\t\", index_col='Row')\n",
    "\n",
    "modules = df['Problem Hierarchy'].unique()\n",
    "\n",
    "# length = len(modules)\n",
    "\n",
    "# list_of_files = glob.glob(\"problem.txt\")\n",
    "# modules = ['sequence General Chemistry I, unit Foundations of Chemistry, module Atomic Theory',\n",
    "#           'sequence General Chemistry I, unit Chemical Reactions, module Chemical Reactions and Equations',\n",
    "#           'sequence General Chemistry I, unit Measurement, module Measurements',\n",
    "#           'sequence General Chemistry I, unit Composition of Substances and Solutions, module Aqueous Solutions',\n",
    "#           'sequence General Chemistry I, unit Reactions and Stoichiometry, module Reaction Stoichiometry']\n",
    "\n",
    "#Is there an easy way to identify the learnersourcing problems? Perhaps we use the feedback text\n",
    "\n",
    "ls_problems = df['Problem Name'].unique()\n",
    "# ls_problems = ['ls_mcqcb4beaaa2978458980cb3faf0553bab7',\n",
    "#                'd76305630f0f41f08928febb2c9d5888',\n",
    "#                'c7266a17a43145eab752c7d9b47ae92d',\n",
    "#                'e79cceb3c3254239b97d561e8a1137a8',\n",
    "#                'c4ab99b22c0e48b583b9d6ae423738de']\n",
    "\n",
    "#These are gathered from the code block above\n",
    "digts = list(digt.keys())\n",
    "lbds = list(lbd.keys())\n",
    "all_data = {}\n",
    "for problem_file in problem_file:\n",
    "    #df = pd.read_csv(problem_file,delimiter=\"\\t\", index_col='Row')\n",
    "\n",
    "    for module in modules:\n",
    "        student_all_act_c_i_s = {}\n",
    "        quiz_correct_and_attempt = {}\n",
    "        #Our dataframe only consists of Atomic Theory problems now\n",
    "        at_df = df.loc[module == df['Problem Hierarchy']]\n",
    "\n",
    "        #Get all student_ids in a list that did atomic theory work\n",
    "        unique_student_ids = df['Anon Student Id'].unique()\n",
    "\n",
    "        for student_id in unique_student_ids:\n",
    "            permod = {}\n",
    "            s_df = at_df.loc[(df['Anon Student Id'] == student_id)]\n",
    "            if not s_df.empty:\n",
    "                #Here we grab the incorrects, corrects, steps, and first attempt totals for all problems the student did\n",
    "                at_q_df = s_df.loc[~at_df['Problem Name'].str.contains('quiz')]\n",
    "                if not at_q_df.empty:\n",
    "                    incorrects = at_q_df['Incorrects'].sum()\n",
    "                    corrects = at_q_df['Corrects'].sum()\n",
    "                    steps = at_q_df['Steps'].sum()\n",
    "                    correct_first_attempts = at_q_df['Correct First Attempts'].sum()\n",
    "                    problems_done = len(pd.unique(at_q_df['Problem Name'])) - 1 #Minus 1 to remove the LS activity\n",
    "                    did_ls = at_q_df.isin(ls_problems).any().any()\n",
    "                    if student_id in all_data.keys():\n",
    "                        all_data[student_id][module] = [incorrects, corrects, steps, correct_first_attempts, problems_done, did_ls]\n",
    "                    else:\n",
    "                        permod[module] = [incorrects, corrects, steps, correct_first_attempts, problems_done, did_ls]\n",
    "                        all_data[student_id] = permod\n",
    "                else:\n",
    "                    if student_id in all_data.keys():\n",
    "                        all_data[student_id][module] = [0, 0, 0, 0, 0, False]\n",
    "                    else:\n",
    "                        permod[module] = [0, 0, 0, 0, 0, False]\n",
    "                        all_data[student_id] = permod\n",
    "            else:\n",
    "                if student_id in all_data.keys():\n",
    "                    all_data[student_id][module] = [0, 0, 0, 0, 0, False]\n",
    "                else:\n",
    "                    permod[module] = [0, 0, 0, 0, 0, False]\n",
    "                    all_data[student_id] = permod\n",
    "\n",
    "#Walk this dictionary to make the desired spreadsheet that contains the total AND broken down by module\n",
    "dfdata = {}\n",
    "for stdnt, moddata in all_data.items():\n",
    "    c = moddata.copy()\n",
    "    totals = [0,0,0,0,0,0]\n",
    "    for mod, data in c.items():\n",
    "        totals[0] += data[0]\n",
    "        totals[1] += data[1]\n",
    "        totals[2] += data[2]\n",
    "        totals[3] += data[3]\n",
    "        totals[4] += data[4]\n",
    "        totals[5] += data[5]\n",
    "\n",
    "        if stdnt in dfdata.keys():\n",
    "            dfdata[stdnt].extend(data)\n",
    "        else:\n",
    "            dfdata[stdnt] = data\n",
    "    dfdata[stdnt].extend(totals)\n",
    "\n",
    "# print(dfdata)\n",
    "\n",
    "df_stu_acts = pd.DataFrame(columns=['stuID', 'prob-hierarchy', 'incorrect', 'correct', 'steps', 'first', 'problems', 'ls'])\n",
    "\n",
    "for k,v in dfdata.items():\n",
    "    ph = 1\n",
    "    for x in range(length):\n",
    "        L = []\n",
    "        L.append(k)\n",
    "        L.append(ph)\n",
    "        L=L+v[6*x:(6*x)+6]\n",
    "        df_stu_acts.loc[len(df_stu_acts)] = L\n",
    "        ph=ph+1\n",
    "\n",
    "\n",
    "# df_student_acts = pd.DataFrame.from_dict(dfdata, orient=\"index\")\n",
    "# df_student_acts.columns = ['incorrect-at', 'correct-at', 'steps-at', 'first-at', 'problems-at', 'ls-at',\n",
    "#                           'incorrect-cre', 'correct-cre', 'steps-cre', 'first-cre', 'problems-cre', 'ls-cre',\n",
    "#                           'incorrect-m', 'correct-m', 'steps-m', 'first-m', 'problems-m', 'ls-m',\n",
    "#                           'incorrect-as', 'correct-as', 'steps-as', 'first-as', 'problems-as', 'ls-as',\n",
    "#                           'incorrect-rs', 'correct-rs', 'steps-rs', 'first-rs', 'problems-rs', 'ls-rs',\n",
    "#                           'incorrect-total', 'correct-total', 'steps-total', 'first-total', 'problems-total', 'ls-total']\n",
    "df_stu_acts.to_csv(outputPath + \"/student_act.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
